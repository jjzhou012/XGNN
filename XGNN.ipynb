{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XGNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn3BhHWoC3LJ",
        "outputId": "a6b9a69a-2c5d-4455-9e59-c06e1456bed6"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwOHpuAZvL97"
      },
      "source": [
        "Meanwhile, for the real-world dataset MUTAG, since all nodes are labeled, we employ the corresponding\r\n",
        "one-hot representations as the initial node features. Then we employ three layers of GCNs with output dimensions equal to 32, 48,\r\n",
        "64 respectively and average all node features. The final classifier\r\n",
        "contains two fully-connected layers in which the hidden dimension\r\n",
        "is set to 32. Note that for all GCN layers, we apply the GCN version\r\n",
        "shown in Equation (1). In addition, we employ Sigmoid as the nonlinear function in GCNs for dataset Is_Acyclic while we use Relu for\r\n",
        "dataset MUTAG. These models are implemented using Pytorch [27]\r\n",
        "and trained using Adam optimizer [18]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP2w7zMwC9Uu",
        "outputId": "06ce6d43-e204-4a4e-d4d5-6798728357ff"
      },
      "source": [
        "# Colab compatitbility\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        " \r\n",
        "%cd /content/drive/My\\ Drive/Colab\\ Notebooks/URECA/XGNN"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/Colab Notebooks/URECA/XGNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWinGsw_T9BS"
      },
      "source": [
        "# Utils\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyJhmxNElNAK"
      },
      "source": [
        "import numpy as np\r\n",
        "import scipy.sparse as sp\r\n",
        "import torch\r\n",
        "\r\n",
        "\r\n",
        "def encode_onehot(labels):\r\n",
        "    classes = set(labels)\r\n",
        "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\r\n",
        "                    enumerate(classes)}\r\n",
        "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\r\n",
        "                             dtype=np.int32)\r\n",
        "    return labels_onehot\r\n",
        "\r\n",
        "\r\n",
        "def load_Mutagenicity_data(path=\"Mutag/\", dataset=\"Mutag\", split_train=0.7, split_val=0.15):\r\n",
        "    \"\"\"Load Mutagenicity data \"\"\"\r\n",
        "    print('Loading {} dataset...'.format(dataset))\r\n",
        "\r\n",
        "    nodeidx_features = np.genfromtxt(\"{}{}.node_labels\".format(path, dataset), delimiter=\",\",\r\n",
        "                                        dtype=np.dtype(int))\r\n",
        "    features = np.zeros((nodeidx_features.shape[0], max(nodeidx_features) + 1))\r\n",
        "    features[np.arange(nodeidx_features.shape[0]), nodeidx_features] = 1\r\n",
        "    features = sp.csr_matrix(features, dtype=np.float32)\r\n",
        "\r\n",
        "    labels = np.genfromtxt(\"{}{}.graph_labels\".format(path, dataset),\r\n",
        "                                        dtype=np.dtype(int))\r\n",
        "    labels = encode_onehot(labels)\r\n",
        "\r\n",
        "    graph_idx = np.genfromtxt(\"{}{}.graph_idx\".format(path, dataset),\r\n",
        "                                        dtype=np.dtype(int))\r\n",
        "    graph_idx = np.array(graph_idx, dtype=np.int32)\r\n",
        "    idx_map = {j: i for i, j in enumerate(graph_idx)}\r\n",
        "\r\n",
        "    edges_unordered = np.genfromtxt(\"{}{}.edges\".format(path, dataset), delimiter=\",\",\r\n",
        "                                    dtype=np.int32)\r\n",
        "    edges_label = np.genfromtxt(\"{}{}.link_labels\".format(path, dataset), delimiter=\",\",\r\n",
        "                                    dtype=np.int32)\r\n",
        "    \r\n",
        "    # According to paper, ignore edge labels\r\n",
        "    # adj = sp.coo_matrix((edges_label, (edges_unordered[:,0]-1, edges_unordered[:,1]-1)))\r\n",
        "    adj = sp.coo_matrix((np.ones(len(edges_label)), (edges_unordered[:,0]-1, edges_unordered[:,1]-1)))\r\n",
        "\r\n",
        "    # build symmetric adjacency matrix\r\n",
        "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\r\n",
        "\r\n",
        "    features = normalize(features)\r\n",
        "    adj = normalize(adj + sp.eye(adj.shape[0]))\r\n",
        "\r\n",
        "    num_total = max(graph_idx)\r\n",
        "    num_train = int(split_train * num_total)\r\n",
        "    num_val = int((split_train + split_val) * num_total)\r\n",
        "\r\n",
        "    if (num_train == num_val or num_val == num_total):\r\n",
        "        return\r\n",
        "\r\n",
        "    idx_train = range(num_train)\r\n",
        "    idx_val = range(num_train,num_val)\r\n",
        "    idx_test = range(num_val, num_total)\r\n",
        "\r\n",
        "    features = torch.FloatTensor(np.array(features.todense()))\r\n",
        "    labels = torch.LongTensor(np.where(labels)[1])\r\n",
        "    adj = sparse_mx_to_torch_sparse_tensor(adj)\r\n",
        "\r\n",
        "    idx_train = torch.LongTensor(idx_train)\r\n",
        "    idx_val = torch.LongTensor(idx_val)\r\n",
        "    idx_test = torch.LongTensor(idx_test)\r\n",
        "\r\n",
        "    return adj, features, labels, idx_map, idx_train, idx_val, idx_test\r\n",
        "\r\n",
        "def load_MUTAG_data(path=\"MUTAG/\", dataset=\"MUTAG_\", split_train=0.7, split_val=0.15):\r\n",
        "    \"\"\"Load MUTAG data \"\"\"\r\n",
        "    print('Loading {} dataset...'.format(dataset))\r\n",
        "\r\n",
        "    nodeidx_features = np.genfromtxt(\"{}{}node_labels.txt\".format(path, dataset), delimiter=\",\",\r\n",
        "                                        dtype=np.dtype(int))\r\n",
        "    features = np.zeros((nodeidx_features.shape[0], max(nodeidx_features) + 1))\r\n",
        "    features[np.arange(nodeidx_features.shape[0]), nodeidx_features] = 1\r\n",
        "    features = sp.csr_matrix(features, dtype=np.float32)\r\n",
        "\r\n",
        "    labels = np.genfromtxt(\"{}{}graph_labels.txt\".format(path, dataset),\r\n",
        "                                        dtype=np.dtype(int))\r\n",
        "    labels = encode_onehot(labels)\r\n",
        "\r\n",
        "    graph_idx = np.genfromtxt(\"{}{}graph_indicator.txt\".format(path, dataset),\r\n",
        "                                        dtype=np.dtype(int))\r\n",
        "    graph_idx = np.array(graph_idx, dtype=np.int32)\r\n",
        "    idx_map = {j: i for i, j in enumerate(graph_idx)}\r\n",
        "\r\n",
        "    edges_unordered = np.genfromtxt(\"{}{}A.txt\".format(path, dataset), delimiter=\",\",\r\n",
        "                                    dtype=np.int32)\r\n",
        "    edges_label = np.genfromtxt(\"{}{}edge_labels.txt\".format(path, dataset), delimiter=\",\",\r\n",
        "                                    dtype=np.int32)\r\n",
        "    adj = sp.coo_matrix((edges_label, (edges_unordered[:,0]-1, edges_unordered[:,1]-1)))\r\n",
        "\r\n",
        "    # build symmetric adjacency matrix\r\n",
        "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\r\n",
        "\r\n",
        "    features = normalize(features)\r\n",
        "    adj = normalize(adj + sp.eye(adj.shape[0]))\r\n",
        "\r\n",
        "    num_total = max(graph_idx)\r\n",
        "    num_train = int(split_train * num_total)\r\n",
        "    num_val = int((split_train + split_val) * num_total)\r\n",
        "\r\n",
        "    if (num_train == num_val or num_val == num_total):\r\n",
        "        return\r\n",
        "\r\n",
        "    idx_train = range(num_train)\r\n",
        "    idx_val = range(num_train,num_val)\r\n",
        "    idx_test = range(num_val, num_total)\r\n",
        "\r\n",
        "    features = torch.FloatTensor(np.array(features.todense()))\r\n",
        "    labels = torch.LongTensor(np.where(labels)[1])\r\n",
        "    adj = sparse_mx_to_torch_sparse_tensor(adj)\r\n",
        "\r\n",
        "    idx_train = torch.LongTensor(idx_train)\r\n",
        "    idx_val = torch.LongTensor(idx_val)\r\n",
        "    idx_test = torch.LongTensor(idx_test)\r\n",
        "\r\n",
        "    return adj, features, labels, idx_map, idx_train, idx_val, idx_test\r\n",
        "\r\n",
        "\r\n",
        "def load_split_MUTAG_data(path=\"MUTAG/\", dataset=\"MUTAG_\", split_train=0.7, split_val=0.15):\r\n",
        "    \"\"\"Load MUTAG data \"\"\"\r\n",
        "    print('Loading {} dataset...'.format(dataset))\r\n",
        "\r\n",
        "    labels = np.genfromtxt(\"{}{}graph_labels.txt\".format(path, dataset),\r\n",
        "                                        dtype=np.dtype(int))\r\n",
        "    labels = encode_onehot(labels)\r\n",
        "    labels = torch.LongTensor(np.where(labels)[1])\r\n",
        "\r\n",
        "    graph_idx = np.genfromtxt(\"{}{}graph_indicator.txt\".format(path, dataset),\r\n",
        "                                        dtype=np.dtype(int))\r\n",
        "    graph_idx = np.array(graph_idx, dtype=np.int32)\r\n",
        "    idx_map = {j: i for i, j in enumerate(graph_idx)}\r\n",
        "    length = len(idx_map.keys())\r\n",
        "    num_nodes = [idx_map[n] - idx_map[n-1] if n-1>1 else idx_map[n] for n in range(1, length+1)]\r\n",
        "    max_num_nodes = max(num_nodes)\r\n",
        "    features_list = []\r\n",
        "    adj_list = []\r\n",
        "    prev = 0\r\n",
        "    \r\n",
        "    nodeidx_features = np.genfromtxt(\"{}{}node_labels.txt\".format(path, dataset), delimiter=\",\",\r\n",
        "                                        dtype=np.dtype(int))\r\n",
        "    features = np.zeros((nodeidx_features.shape[0], max(nodeidx_features) + 1))\r\n",
        "    features[np.arange(nodeidx_features.shape[0]), nodeidx_features] = 1\r\n",
        "\r\n",
        "    edges_unordered = np.genfromtxt(\"{}{}A.txt\".format(path, dataset), delimiter=\",\",\r\n",
        "                                    dtype=np.int32)\r\n",
        "    edges_label = np.genfromtxt(\"{}{}edge_labels.txt\".format(path, dataset), delimiter=\",\",\r\n",
        "                                    dtype=np.int32)\r\n",
        "    adj = sp.coo_matrix((edges_label, (edges_unordered[:,0]-1, edges_unordered[:,1]-1)))\r\n",
        "\r\n",
        "    # build symmetric adjacency matrix\r\n",
        "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\r\n",
        "\r\n",
        "    features = normalize(features)\r\n",
        "    adj = normalize(adj + sp.eye(adj.shape[0]))\r\n",
        "    adj = adj.todense()\r\n",
        "\r\n",
        "    for n in range(1, length+1):\r\n",
        "        entry = np.zeros((max_num_nodes, max(nodeidx_features) + 1))\r\n",
        "        entry[:idx_map[n] - prev] = features[prev:idx_map[n]]\r\n",
        "        entry = torch.FloatTensor(entry)\r\n",
        "        features_list.append(entry)\r\n",
        "        \r\n",
        "        entry = np.zeros((max_num_nodes, max_num_nodes))\r\n",
        "        entry[:idx_map[n] - prev, :idx_map[n] - prev] = adj[prev:idx_map[n], prev:idx_map[n]]\r\n",
        "        entry = torch.FloatTensor(entry)\r\n",
        "        adj_list.append(entry)\r\n",
        "\r\n",
        "        prev = idx_map[n]\r\n",
        "\r\n",
        "    num_total = max(graph_idx)\r\n",
        "    num_train = int(split_train * num_total)\r\n",
        "    num_val = int((split_train + split_val) * num_total)\r\n",
        "\r\n",
        "    if (num_train == num_val or num_val == num_total):\r\n",
        "        return\r\n",
        "\r\n",
        "    idx_train = range(num_train)\r\n",
        "    idx_val = range(num_train,num_val)\r\n",
        "    idx_test = range(num_val, num_total)\r\n",
        "\r\n",
        "    idx_train = torch.LongTensor(idx_train)\r\n",
        "    idx_val = torch.LongTensor(idx_val)\r\n",
        "    idx_test = torch.LongTensor(idx_test)\r\n",
        "\r\n",
        "    return adj_list, features_list, labels, idx_map, idx_train, idx_val, idx_test\r\n",
        "\r\n",
        "def normalize(mx):\r\n",
        "    \"\"\"Row-normalize sparse matrix\"\"\"\r\n",
        "    rowsum = np.array(mx.sum(1))\r\n",
        "    r_inv = np.power(rowsum, -1).flatten()\r\n",
        "    r_inv[np.isinf(r_inv)] = 0.\r\n",
        "    r_mat_inv = sp.diags(r_inv)\r\n",
        "    mx = r_mat_inv.dot(mx)\r\n",
        "    return mx\r\n",
        "\r\n",
        "\r\n",
        "def accuracy(output, labels):\r\n",
        "    preds = output.max(1)[1].type_as(labels)\r\n",
        "    correct = preds.eq(labels).double()\r\n",
        "    correct = correct.sum()\r\n",
        "    return correct / len(labels)\r\n",
        "\r\n",
        "\r\n",
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\r\n",
        "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\r\n",
        "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\r\n",
        "    indices = torch.from_numpy(\r\n",
        "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\r\n",
        "    values = torch.from_numpy(sparse_mx.data)\r\n",
        "    shape = torch.Size(sparse_mx.shape)\r\n",
        "    return torch.sparse.FloatTensor(indices, values, shape)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5plpJwEf2OIn"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfvnkXBf2dwA"
      },
      "source": [
        "Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZZgY1uX2c64"
      },
      "source": [
        "import math\r\n",
        "\r\n",
        "import torch\r\n",
        "\r\n",
        "from torch.nn.parameter import Parameter\r\n",
        "from torch.nn.modules.module import Module\r\n",
        "\r\n",
        "\r\n",
        "class GraphConvolution(Module):\r\n",
        "    \"\"\"\r\n",
        "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, in_features, out_features, bias=True):\r\n",
        "        super(GraphConvolution, self).__init__()\r\n",
        "        self.in_features = in_features\r\n",
        "        self.out_features = out_features\r\n",
        "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\r\n",
        "        if bias:\r\n",
        "            self.bias = Parameter(torch.FloatTensor(out_features))\r\n",
        "        else:\r\n",
        "            self.register_parameter('bias', None)\r\n",
        "        self.reset_parameters()\r\n",
        "\r\n",
        "    def reset_parameters(self):\r\n",
        "        stdv = 1. / math.sqrt(self.weight.size(1))\r\n",
        "        self.weight.data.uniform_(-stdv, stdv)\r\n",
        "        if self.bias is not None:\r\n",
        "            self.bias.data.uniform_(-stdv, stdv)\r\n",
        "\r\n",
        "    def forward(self, input, adj):\r\n",
        "        support = torch.mm(input, self.weight)\r\n",
        "        output = torch.spmm(adj, support)\r\n",
        "        if self.bias is not None:\r\n",
        "            return output + self.bias\r\n",
        "        else:\r\n",
        "            return output\r\n",
        "\r\n",
        "    def __repr__(self):\r\n",
        "        return self.__class__.__name__ + ' (' \\\r\n",
        "               + str(self.in_features) + ' -> ' \\\r\n",
        "               + str(self.out_features) + ')'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSGqO7HQ2xM1"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-7MdEYQ2RJ8"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "class GCN(nn.Module):\r\n",
        "    def __init__(self, nfeat, nclass, dropout):\r\n",
        "        \"\"\" As per paper \"\"\"\r\n",
        "        \"\"\" 3 layers of GCNs with output dimensions equal to 32, 48, 64 respectively and average all node features \"\"\"\r\n",
        "        \"\"\" Final classifier with 2 fully connected layers and hidden dimension set to 32 \"\"\"\r\n",
        "        \"\"\" Activation function - ReLu (Mutag) \"\"\"\r\n",
        "\r\n",
        "        super(GCN, self).__init__()\r\n",
        "\r\n",
        "        self.dropout = dropout\r\n",
        "\r\n",
        "        self.gc1 = GraphConvolution(nfeat, 32)\r\n",
        "        self.gc2 = GraphConvolution(32, 48)\r\n",
        "        self.gc3 = GraphConvolution(48, 64)\r\n",
        "        self.fc1 = nn.Linear(64, 32)\r\n",
        "        self.fc2 = nn.Linear(32, nclass)\r\n",
        "\r\n",
        "    def forward(self, x, adj, idx_map):\r\n",
        "\r\n",
        "        x = F.relu(self.gc1(x, adj))\r\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\r\n",
        "        x = F.relu(self.gc2(x, adj))\r\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\r\n",
        "        x = F.relu(self.gc3(x, adj))\r\n",
        "\r\n",
        "        # prev = 0\r\n",
        "        # y = []\r\n",
        "        # for idx in idx_map:\r\n",
        "        #   y.append(torch.mean(x[prev:idx_map[idx]], 0))\r\n",
        "        #   prev = idx_map[idx]\r\n",
        "        # y = torch.stack(y, 0)\r\n",
        "\r\n",
        "        y = torch.mean(x, 0)\r\n",
        "\r\n",
        "        y = F.relu(self.fc1(y))\r\n",
        "        y = F.dropout(y, self.dropout, training=self.training)\r\n",
        "        y = F.softmax(self.fc2(y), dim=0)\r\n",
        "\r\n",
        "        return y"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP4drwZjCg2z"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq4q5O-tqQW5",
        "outputId": "28d28d8a-0337-4a78-9906-9c4353ebe652"
      },
      "source": [
        "# Load data\r\n",
        "# adj, features, labels, idx_map, idx_train, idx_val, idx_test = load_MUTAG_data()\r\n",
        "adj_list, features_list, labels, idx_map, idx_train, idx_val, idx_test = load_split_MUTAG_data()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading MUTAG_ dataset...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXQRRd-mAsAe"
      },
      "source": [
        "from __future__ import division\r\n",
        "from __future__ import print_function\r\n",
        "\r\n",
        "import time\r\n",
        "import argparse\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "\r\n",
        "# Parameters\r\n",
        "\r\n",
        "class Object(object):\r\n",
        "    pass\r\n",
        "\r\n",
        "args = Object()\r\n",
        "args.epochs = 80\r\n",
        "args.seed = 200\r\n",
        "args.cuda = torch.cuda.is_available()\r\n",
        "args.lr = 0.001\r\n",
        "args.dropout = 0.1\r\n",
        "args.weight_decay = 5e-4\r\n",
        "\r\n",
        "np.random.seed(args.seed)\r\n",
        "torch.manual_seed(args.seed)\r\n",
        "if args.cuda:\r\n",
        "    torch.cuda.manual_seed(args.seed)\r\n",
        "\r\n",
        "# Model and optimizer\r\n",
        "\r\n",
        "# model = GCN(nfeat=features.shape[1],\r\n",
        "#             nclass=labels.max().item() + 1,\r\n",
        "#             dropout=args.dropout)\r\n",
        "\r\n",
        "model = GCN(nfeat=features_list[0].shape[1],\r\n",
        "            nclass=labels.max().item() + 1,\r\n",
        "            dropout=args.dropout)\r\n",
        "\r\n",
        "optimizer = optim.Adam(model.parameters(),\r\n",
        "                       lr=args.lr, weight_decay=args.weight_decay)\r\n",
        "\r\n",
        "# if args.cuda:\r\n",
        "#     model.cuda()\r\n",
        "#     features = features.cuda()\r\n",
        "#     adj = adj.cuda()\r\n",
        "#     labels = labels.cuda()\r\n",
        "#     idx_train = idx_train.cuda()\r\n",
        "#     idx_val = idx_val.cuda()\r\n",
        "#     idx_test = idx_test.cuda()\r\n",
        "\r\n",
        "if args.cuda:\r\n",
        "    model.cuda()\r\n",
        "    features = features_list.cuda()\r\n",
        "    adj = adj_list.cuda()\r\n",
        "    labels = labels.cuda()\r\n",
        "    idx_train = idx_train.cuda()\r\n",
        "    idx_val = idx_val.cuda()\r\n",
        "    idx_test = idx_test.cuda()\r\n",
        "\r\n",
        "def train(epoch):\r\n",
        "    t = time.time()\r\n",
        "    model.train()\r\n",
        "    optimizer.zero_grad()\r\n",
        "\r\n",
        "    # # Split\r\n",
        "    output = None\r\n",
        "    for i in idx_train:\r\n",
        "      if output is None:\r\n",
        "        output = model(features_list[i], adj_list[i], idx_map)\r\n",
        "      else:\r\n",
        "        output = torch.vstack((output, model(features_list[i], adj_list[i], idx_map)))\r\n",
        "    loss_train = F.cross_entropy(output, labels[idx_train])\r\n",
        "    acc_train = accuracy(output, labels[idx_train])\r\n",
        "    loss_train.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    model.eval()\r\n",
        "    output = None\r\n",
        "    for i in idx_val:\r\n",
        "      if output is None:\r\n",
        "        output = model(features_list[i], adj_list[i], idx_map)\r\n",
        "      else:\r\n",
        "        output = torch.vstack((output, model(features_list[i], adj_list[i], idx_map)))\r\n",
        "    loss_val = F.cross_entropy(output, labels[idx_val])\r\n",
        "    acc_val = accuracy(output, labels[idx_val])\r\n",
        "\r\n",
        "    # # Not split\r\n",
        "    # output = model(features, adj, idx_map)\r\n",
        "    # TODO : Determine LOSS FUNCTION\r\n",
        "    # loss_train = F.cross_entropy(output[idx_train], labels[idx_train])\r\n",
        "    # acc_train = accuracy(output[idx_train], labels[idx_train])\r\n",
        "    # loss_train.backward()\r\n",
        "    # optimizer.step()\r\n",
        "\r\n",
        "    # loss_val = F.cross_entropy(output[idx_val], labels[idx_val])\r\n",
        "    # acc_val = accuracy(output[idx_val], labels[idx_val])\r\n",
        "\r\n",
        "    print('Epoch: {:04d}'.format(epoch+1),\r\n",
        "          'loss_train: {:.4f}'.format(loss_train.item()),\r\n",
        "          'acc_train: {:.4f}'.format(acc_train.item()),\r\n",
        "          'loss_val: {:.4f}'.format(loss_val.item()),\r\n",
        "          'acc_val: {:.4f}'.format(acc_val.item()),\r\n",
        "          'time: {:.4f}s'.format(time.time() - t))\r\n",
        "    \r\n",
        "    return loss_train, acc_train, loss_val, acc_val\r\n",
        "\r\n",
        "class EarlyStopping():\r\n",
        "    def __init__(self, patience = 10, min_loss = 0.5, hit_min_before_stopping = False):\r\n",
        "        self.patience = patience\r\n",
        "        self.counter = 0\r\n",
        "        self.hit_min_before_stopping = hit_min_before_stopping\r\n",
        "        if hit_min_before_stopping:\r\n",
        "            self.min_loss = min_loss\r\n",
        "        self.best_loss = None\r\n",
        "        self.early_stop = False\r\n",
        "        \r\n",
        "    def __call__(self, loss):\r\n",
        "        if self.best_loss is None:\r\n",
        "            self.best_loss = loss\r\n",
        "        elif loss > self.best_loss:\r\n",
        "            self.counter += 1\r\n",
        "            if self.counter > self.patience:\r\n",
        "              if self.hit_min_before_stopping == True and loss > self.min_loss:\r\n",
        "                print(\"Cannot hit mean loss, will continue\")\r\n",
        "                self.counter -= self.patience\r\n",
        "              else:\r\n",
        "                self.early_stop = True\r\n",
        "        else:\r\n",
        "            self.best_loss = loss\r\n",
        "            counter = 0"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EPXCB8uu928",
        "outputId": "9b9cd19f-b232-4d81-b84e-34e0658f977b"
      },
      "source": [
        "# Train model\r\n",
        "t_total = time.time()\r\n",
        "early_stopping = EarlyStopping(10, hit_min_before_stopping=True)\r\n",
        "\r\n",
        "for epoch in range(10000):\r\n",
        "    loss_train, acc_train, loss_val, acc_val = train(epoch)\r\n",
        "    print(loss_val)\r\n",
        "    early_stopping(loss_val)\r\n",
        "    if early_stopping.early_stop == True:\r\n",
        "        break;\r\n",
        "\r\n",
        "print(\"Optimization Finished!\")\r\n",
        "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 loss_train: 0.7123 acc_train: 0.3053 loss_val: 0.6930 acc_val: 0.5000 time: 0.1256s\n",
            "tensor(0.6930, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0002 loss_train: 0.7084 acc_train: 0.3053 loss_val: 0.6932 acc_val: 0.5000 time: 0.1132s\n",
            "tensor(0.6932, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0003 loss_train: 0.7073 acc_train: 0.3053 loss_val: 0.6949 acc_val: 0.5000 time: 0.1162s\n",
            "tensor(0.6949, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0004 loss_train: 0.7050 acc_train: 0.3053 loss_val: 0.6927 acc_val: 0.5000 time: 0.1244s\n",
            "tensor(0.6927, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0005 loss_train: 0.7034 acc_train: 0.3053 loss_val: 0.6914 acc_val: 0.5000 time: 0.1252s\n",
            "tensor(0.6914, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0006 loss_train: 0.7007 acc_train: 0.3053 loss_val: 0.6946 acc_val: 0.5000 time: 0.1391s\n",
            "tensor(0.6946, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0007 loss_train: 0.7000 acc_train: 0.3053 loss_val: 0.6911 acc_val: 0.5000 time: 0.1259s\n",
            "tensor(0.6911, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0008 loss_train: 0.6984 acc_train: 0.3053 loss_val: 0.6931 acc_val: 0.5000 time: 0.1171s\n",
            "tensor(0.6931, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0009 loss_train: 0.6965 acc_train: 0.3130 loss_val: 0.6906 acc_val: 0.5357 time: 0.1219s\n",
            "tensor(0.6906, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0010 loss_train: 0.6942 acc_train: 0.4504 loss_val: 0.6919 acc_val: 0.5357 time: 0.1261s\n",
            "tensor(0.6919, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0011 loss_train: 0.6925 acc_train: 0.4885 loss_val: 0.6928 acc_val: 0.5714 time: 0.1254s\n",
            "tensor(0.6928, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0012 loss_train: 0.6917 acc_train: 0.6336 loss_val: 0.6923 acc_val: 0.5000 time: 0.1167s\n",
            "tensor(0.6923, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0013 loss_train: 0.6904 acc_train: 0.6489 loss_val: 0.6920 acc_val: 0.5357 time: 0.1329s\n",
            "tensor(0.6920, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0014 loss_train: 0.6886 acc_train: 0.6870 loss_val: 0.6935 acc_val: 0.5000 time: 0.1190s\n",
            "tensor(0.6935, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0015 loss_train: 0.6882 acc_train: 0.6641 loss_val: 0.6919 acc_val: 0.4643 time: 0.1331s\n",
            "tensor(0.6919, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0016 loss_train: 0.6860 acc_train: 0.6870 loss_val: 0.6921 acc_val: 0.5000 time: 0.1458s\n",
            "tensor(0.6921, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0017 loss_train: 0.6848 acc_train: 0.7099 loss_val: 0.6922 acc_val: 0.5000 time: 0.1298s\n",
            "tensor(0.6922, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0018 loss_train: 0.6831 acc_train: 0.7023 loss_val: 0.6900 acc_val: 0.5000 time: 0.1194s\n",
            "tensor(0.6900, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0019 loss_train: 0.6816 acc_train: 0.7023 loss_val: 0.6933 acc_val: 0.5000 time: 0.1178s\n",
            "tensor(0.6933, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0020 loss_train: 0.6800 acc_train: 0.6947 loss_val: 0.6906 acc_val: 0.5000 time: 0.1446s\n",
            "tensor(0.6906, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0021 loss_train: 0.6803 acc_train: 0.7023 loss_val: 0.6897 acc_val: 0.5000 time: 0.1220s\n",
            "tensor(0.6897, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0022 loss_train: 0.6782 acc_train: 0.6947 loss_val: 0.6911 acc_val: 0.5000 time: 0.1207s\n",
            "tensor(0.6911, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0023 loss_train: 0.6762 acc_train: 0.6947 loss_val: 0.6915 acc_val: 0.5000 time: 0.1230s\n",
            "tensor(0.6915, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0024 loss_train: 0.6736 acc_train: 0.6947 loss_val: 0.6924 acc_val: 0.5000 time: 0.1169s\n",
            "tensor(0.6924, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0025 loss_train: 0.6747 acc_train: 0.6947 loss_val: 0.6932 acc_val: 0.5000 time: 0.1222s\n",
            "tensor(0.6932, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0026 loss_train: 0.6722 acc_train: 0.6947 loss_val: 0.6908 acc_val: 0.5000 time: 0.1183s\n",
            "tensor(0.6908, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0027 loss_train: 0.6695 acc_train: 0.6947 loss_val: 0.6928 acc_val: 0.5000 time: 0.1231s\n",
            "tensor(0.6928, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0028 loss_train: 0.6687 acc_train: 0.6947 loss_val: 0.6917 acc_val: 0.5000 time: 0.1269s\n",
            "tensor(0.6917, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0029 loss_train: 0.6664 acc_train: 0.6947 loss_val: 0.6919 acc_val: 0.5000 time: 0.1264s\n",
            "tensor(0.6919, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0030 loss_train: 0.6644 acc_train: 0.6947 loss_val: 0.6898 acc_val: 0.5000 time: 0.1267s\n",
            "tensor(0.6898, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0031 loss_train: 0.6617 acc_train: 0.6947 loss_val: 0.6894 acc_val: 0.5000 time: 0.1245s\n",
            "tensor(0.6894, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0032 loss_train: 0.6619 acc_train: 0.6947 loss_val: 0.6896 acc_val: 0.5000 time: 0.1255s\n",
            "tensor(0.6896, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0033 loss_train: 0.6592 acc_train: 0.6947 loss_val: 0.6913 acc_val: 0.5000 time: 0.1427s\n",
            "tensor(0.6913, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0034 loss_train: 0.6574 acc_train: 0.6947 loss_val: 0.6875 acc_val: 0.5000 time: 0.1174s\n",
            "tensor(0.6875, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0035 loss_train: 0.6563 acc_train: 0.6947 loss_val: 0.6872 acc_val: 0.5000 time: 0.1291s\n",
            "tensor(0.6872, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0036 loss_train: 0.6526 acc_train: 0.6947 loss_val: 0.6901 acc_val: 0.5000 time: 0.1245s\n",
            "tensor(0.6901, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0037 loss_train: 0.6504 acc_train: 0.6947 loss_val: 0.6897 acc_val: 0.5000 time: 0.1205s\n",
            "tensor(0.6897, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0038 loss_train: 0.6479 acc_train: 0.6947 loss_val: 0.6924 acc_val: 0.5000 time: 0.1168s\n",
            "tensor(0.6924, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0039 loss_train: 0.6454 acc_train: 0.6947 loss_val: 0.6909 acc_val: 0.5000 time: 0.1173s\n",
            "tensor(0.6909, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0040 loss_train: 0.6430 acc_train: 0.6947 loss_val: 0.6867 acc_val: 0.5000 time: 0.1114s\n",
            "tensor(0.6867, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0041 loss_train: 0.6418 acc_train: 0.6947 loss_val: 0.6837 acc_val: 0.5000 time: 0.1188s\n",
            "tensor(0.6837, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0042 loss_train: 0.6371 acc_train: 0.6947 loss_val: 0.6896 acc_val: 0.5000 time: 0.1129s\n",
            "tensor(0.6896, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0043 loss_train: 0.6338 acc_train: 0.6947 loss_val: 0.6860 acc_val: 0.5000 time: 0.1215s\n",
            "tensor(0.6860, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0044 loss_train: 0.6305 acc_train: 0.6947 loss_val: 0.6832 acc_val: 0.5000 time: 0.1192s\n",
            "tensor(0.6832, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0045 loss_train: 0.6304 acc_train: 0.6947 loss_val: 0.6835 acc_val: 0.5000 time: 0.1219s\n",
            "tensor(0.6835, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0046 loss_train: 0.6277 acc_train: 0.6947 loss_val: 0.6961 acc_val: 0.5000 time: 0.1175s\n",
            "tensor(0.6961, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0047 loss_train: 0.6203 acc_train: 0.6947 loss_val: 0.6878 acc_val: 0.5000 time: 0.1194s\n",
            "tensor(0.6878, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0048 loss_train: 0.6214 acc_train: 0.6947 loss_val: 0.6934 acc_val: 0.5000 time: 0.1135s\n",
            "tensor(0.6934, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0049 loss_train: 0.6114 acc_train: 0.6947 loss_val: 0.6891 acc_val: 0.5000 time: 0.1229s\n",
            "tensor(0.6891, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0050 loss_train: 0.6077 acc_train: 0.6947 loss_val: 0.6928 acc_val: 0.5000 time: 0.1166s\n",
            "tensor(0.6928, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0051 loss_train: 0.6151 acc_train: 0.6947 loss_val: 0.6950 acc_val: 0.5000 time: 0.1197s\n",
            "tensor(0.6950, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0052 loss_train: 0.6077 acc_train: 0.6947 loss_val: 0.6921 acc_val: 0.5000 time: 0.1213s\n",
            "tensor(0.6921, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0053 loss_train: 0.6037 acc_train: 0.6947 loss_val: 0.6880 acc_val: 0.5000 time: 0.1164s\n",
            "tensor(0.6880, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0054 loss_train: 0.6032 acc_train: 0.6947 loss_val: 0.7084 acc_val: 0.5000 time: 0.1128s\n",
            "tensor(0.7084, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0055 loss_train: 0.6010 acc_train: 0.6947 loss_val: 0.7026 acc_val: 0.5000 time: 0.1257s\n",
            "tensor(0.7026, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0056 loss_train: 0.5938 acc_train: 0.6947 loss_val: 0.7140 acc_val: 0.5000 time: 0.1129s\n",
            "tensor(0.7140, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0057 loss_train: 0.5924 acc_train: 0.6947 loss_val: 0.7072 acc_val: 0.5000 time: 0.1164s\n",
            "tensor(0.7072, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0058 loss_train: 0.5953 acc_train: 0.6947 loss_val: 0.7052 acc_val: 0.5000 time: 0.1182s\n",
            "tensor(0.7052, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0059 loss_train: 0.5917 acc_train: 0.6947 loss_val: 0.7120 acc_val: 0.5000 time: 0.1180s\n",
            "tensor(0.7120, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0060 loss_train: 0.5927 acc_train: 0.6947 loss_val: 0.7093 acc_val: 0.5000 time: 0.1156s\n",
            "tensor(0.7093, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0061 loss_train: 0.5921 acc_train: 0.6947 loss_val: 0.7261 acc_val: 0.5000 time: 0.1330s\n",
            "tensor(0.7261, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0062 loss_train: 0.5917 acc_train: 0.6947 loss_val: 0.7262 acc_val: 0.5000 time: 0.1163s\n",
            "tensor(0.7262, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0063 loss_train: 0.5926 acc_train: 0.6947 loss_val: 0.7172 acc_val: 0.5000 time: 0.1197s\n",
            "tensor(0.7172, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0064 loss_train: 0.5913 acc_train: 0.6947 loss_val: 0.7238 acc_val: 0.5000 time: 0.1138s\n",
            "tensor(0.7238, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0065 loss_train: 0.5866 acc_train: 0.6947 loss_val: 0.7181 acc_val: 0.5000 time: 0.1347s\n",
            "tensor(0.7181, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0066 loss_train: 0.5904 acc_train: 0.6947 loss_val: 0.7344 acc_val: 0.5000 time: 0.1198s\n",
            "tensor(0.7344, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0067 loss_train: 0.5918 acc_train: 0.6947 loss_val: 0.7256 acc_val: 0.5000 time: 0.1178s\n",
            "tensor(0.7256, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0068 loss_train: 0.5945 acc_train: 0.6947 loss_val: 0.7372 acc_val: 0.5000 time: 0.1146s\n",
            "tensor(0.7372, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0069 loss_train: 0.5964 acc_train: 0.6947 loss_val: 0.7306 acc_val: 0.5000 time: 0.1263s\n",
            "tensor(0.7306, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0070 loss_train: 0.5953 acc_train: 0.6947 loss_val: 0.7277 acc_val: 0.5000 time: 0.1334s\n",
            "tensor(0.7277, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0071 loss_train: 0.5929 acc_train: 0.6947 loss_val: 0.7426 acc_val: 0.5000 time: 0.1196s\n",
            "tensor(0.7426, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0072 loss_train: 0.5888 acc_train: 0.6947 loss_val: 0.7283 acc_val: 0.5000 time: 0.1168s\n",
            "tensor(0.7283, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0073 loss_train: 0.5951 acc_train: 0.6947 loss_val: 0.7344 acc_val: 0.5000 time: 0.1183s\n",
            "tensor(0.7344, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0074 loss_train: 0.5929 acc_train: 0.6947 loss_val: 0.7333 acc_val: 0.5000 time: 0.1222s\n",
            "tensor(0.7333, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0075 loss_train: 0.5937 acc_train: 0.6947 loss_val: 0.7329 acc_val: 0.5000 time: 0.1214s\n",
            "tensor(0.7329, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0076 loss_train: 0.5914 acc_train: 0.6947 loss_val: 0.7208 acc_val: 0.5000 time: 0.1166s\n",
            "tensor(0.7208, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0077 loss_train: 0.5878 acc_train: 0.6947 loss_val: 0.7222 acc_val: 0.5000 time: 0.1352s\n",
            "tensor(0.7222, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0078 loss_train: 0.5948 acc_train: 0.6947 loss_val: 0.7271 acc_val: 0.5000 time: 0.1142s\n",
            "tensor(0.7271, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0079 loss_train: 0.5895 acc_train: 0.6947 loss_val: 0.7306 acc_val: 0.5000 time: 0.1216s\n",
            "tensor(0.7306, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0080 loss_train: 0.5927 acc_train: 0.6947 loss_val: 0.7218 acc_val: 0.5000 time: 0.1165s\n",
            "tensor(0.7218, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0081 loss_train: 0.5877 acc_train: 0.6947 loss_val: 0.7189 acc_val: 0.5000 time: 0.1231s\n",
            "tensor(0.7189, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0082 loss_train: 0.5884 acc_train: 0.6947 loss_val: 0.7273 acc_val: 0.5000 time: 0.1155s\n",
            "tensor(0.7273, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0083 loss_train: 0.5908 acc_train: 0.6947 loss_val: 0.7189 acc_val: 0.5000 time: 0.1242s\n",
            "tensor(0.7189, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0084 loss_train: 0.5826 acc_train: 0.6947 loss_val: 0.7132 acc_val: 0.5000 time: 0.1180s\n",
            "tensor(0.7132, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0085 loss_train: 0.5880 acc_train: 0.6947 loss_val: 0.7227 acc_val: 0.5000 time: 0.1327s\n",
            "tensor(0.7227, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0086 loss_train: 0.5897 acc_train: 0.6947 loss_val: 0.7213 acc_val: 0.5000 time: 0.1167s\n",
            "tensor(0.7213, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0087 loss_train: 0.5895 acc_train: 0.6947 loss_val: 0.7118 acc_val: 0.5000 time: 0.1205s\n",
            "tensor(0.7118, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0088 loss_train: 0.5894 acc_train: 0.6947 loss_val: 0.7346 acc_val: 0.5000 time: 0.1185s\n",
            "tensor(0.7346, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0089 loss_train: 0.5869 acc_train: 0.6947 loss_val: 0.7043 acc_val: 0.5000 time: 0.1210s\n",
            "tensor(0.7043, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0090 loss_train: 0.5838 acc_train: 0.6947 loss_val: 0.7258 acc_val: 0.5000 time: 0.1202s\n",
            "tensor(0.7258, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0091 loss_train: 0.5852 acc_train: 0.6947 loss_val: 0.7157 acc_val: 0.5000 time: 0.1272s\n",
            "tensor(0.7157, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0092 loss_train: 0.5858 acc_train: 0.6947 loss_val: 0.7177 acc_val: 0.5000 time: 0.1227s\n",
            "tensor(0.7177, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0093 loss_train: 0.5871 acc_train: 0.6947 loss_val: 0.7149 acc_val: 0.5000 time: 0.1333s\n",
            "tensor(0.7149, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0094 loss_train: 0.5875 acc_train: 0.6947 loss_val: 0.7097 acc_val: 0.5000 time: 0.1158s\n",
            "tensor(0.7097, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0095 loss_train: 0.5850 acc_train: 0.6947 loss_val: 0.7222 acc_val: 0.5000 time: 0.1226s\n",
            "tensor(0.7222, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0096 loss_train: 0.5865 acc_train: 0.6947 loss_val: 0.7096 acc_val: 0.5000 time: 0.1370s\n",
            "tensor(0.7096, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0097 loss_train: 0.5858 acc_train: 0.6947 loss_val: 0.7143 acc_val: 0.5000 time: 0.1247s\n",
            "tensor(0.7143, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0098 loss_train: 0.5809 acc_train: 0.6947 loss_val: 0.7075 acc_val: 0.5000 time: 0.1215s\n",
            "tensor(0.7075, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0099 loss_train: 0.5873 acc_train: 0.6947 loss_val: 0.7044 acc_val: 0.5000 time: 0.1186s\n",
            "tensor(0.7044, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0100 loss_train: 0.5876 acc_train: 0.6947 loss_val: 0.7137 acc_val: 0.5000 time: 0.1145s\n",
            "tensor(0.7137, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0101 loss_train: 0.5868 acc_train: 0.6947 loss_val: 0.7055 acc_val: 0.5000 time: 0.1278s\n",
            "tensor(0.7055, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0102 loss_train: 0.5846 acc_train: 0.6947 loss_val: 0.7118 acc_val: 0.5000 time: 0.1137s\n",
            "tensor(0.7118, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0103 loss_train: 0.5874 acc_train: 0.6947 loss_val: 0.6930 acc_val: 0.5000 time: 0.1183s\n",
            "tensor(0.6930, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0104 loss_train: 0.5847 acc_train: 0.6947 loss_val: 0.6980 acc_val: 0.5000 time: 0.1179s\n",
            "tensor(0.6980, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0105 loss_train: 0.5855 acc_train: 0.6947 loss_val: 0.7210 acc_val: 0.5000 time: 0.1171s\n",
            "tensor(0.7210, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0106 loss_train: 0.5807 acc_train: 0.6947 loss_val: 0.7101 acc_val: 0.5000 time: 0.1176s\n",
            "tensor(0.7101, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0107 loss_train: 0.5834 acc_train: 0.6947 loss_val: 0.7104 acc_val: 0.5000 time: 0.1484s\n",
            "tensor(0.7104, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0108 loss_train: 0.5841 acc_train: 0.6947 loss_val: 0.7015 acc_val: 0.5000 time: 0.1170s\n",
            "tensor(0.7015, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0109 loss_train: 0.5844 acc_train: 0.6947 loss_val: 0.7080 acc_val: 0.5000 time: 0.1296s\n",
            "tensor(0.7080, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0110 loss_train: 0.5861 acc_train: 0.6947 loss_val: 0.7080 acc_val: 0.5000 time: 0.1180s\n",
            "tensor(0.7080, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0111 loss_train: 0.5838 acc_train: 0.6947 loss_val: 0.7137 acc_val: 0.5000 time: 0.1204s\n",
            "tensor(0.7137, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0112 loss_train: 0.5846 acc_train: 0.6947 loss_val: 0.6983 acc_val: 0.5000 time: 0.1161s\n",
            "tensor(0.6983, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0113 loss_train: 0.5859 acc_train: 0.6947 loss_val: 0.7048 acc_val: 0.5000 time: 0.1313s\n",
            "tensor(0.7048, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0114 loss_train: 0.5818 acc_train: 0.6947 loss_val: 0.6982 acc_val: 0.5000 time: 0.1226s\n",
            "tensor(0.6982, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0115 loss_train: 0.5848 acc_train: 0.6947 loss_val: 0.6979 acc_val: 0.5000 time: 0.1266s\n",
            "tensor(0.6979, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0116 loss_train: 0.5856 acc_train: 0.6947 loss_val: 0.7023 acc_val: 0.5000 time: 0.1257s\n",
            "tensor(0.7023, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0117 loss_train: 0.5858 acc_train: 0.6947 loss_val: 0.7125 acc_val: 0.5000 time: 0.1388s\n",
            "tensor(0.7125, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0118 loss_train: 0.5843 acc_train: 0.6947 loss_val: 0.7000 acc_val: 0.5000 time: 0.1260s\n",
            "tensor(0.7000, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0119 loss_train: 0.5851 acc_train: 0.6947 loss_val: 0.6930 acc_val: 0.5000 time: 0.1204s\n",
            "tensor(0.6930, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0120 loss_train: 0.5831 acc_train: 0.6947 loss_val: 0.7102 acc_val: 0.5000 time: 0.1158s\n",
            "tensor(0.7102, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0121 loss_train: 0.5865 acc_train: 0.6947 loss_val: 0.6919 acc_val: 0.5000 time: 0.1311s\n",
            "tensor(0.6919, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0122 loss_train: 0.5814 acc_train: 0.6947 loss_val: 0.7052 acc_val: 0.5000 time: 0.1279s\n",
            "tensor(0.7052, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0123 loss_train: 0.5829 acc_train: 0.6947 loss_val: 0.6903 acc_val: 0.5000 time: 0.1226s\n",
            "tensor(0.6903, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0124 loss_train: 0.5848 acc_train: 0.6947 loss_val: 0.6882 acc_val: 0.5000 time: 0.1327s\n",
            "tensor(0.6882, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0125 loss_train: 0.5821 acc_train: 0.6947 loss_val: 0.6932 acc_val: 0.5000 time: 0.1246s\n",
            "tensor(0.6932, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0126 loss_train: 0.5765 acc_train: 0.6947 loss_val: 0.6865 acc_val: 0.5000 time: 0.1202s\n",
            "tensor(0.6865, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0127 loss_train: 0.5793 acc_train: 0.6947 loss_val: 0.6889 acc_val: 0.5000 time: 0.1256s\n",
            "tensor(0.6889, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0128 loss_train: 0.5793 acc_train: 0.6947 loss_val: 0.6972 acc_val: 0.5000 time: 0.1220s\n",
            "tensor(0.6972, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0129 loss_train: 0.5763 acc_train: 0.6947 loss_val: 0.6980 acc_val: 0.5000 time: 0.1228s\n",
            "tensor(0.6980, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0130 loss_train: 0.5793 acc_train: 0.6947 loss_val: 0.6991 acc_val: 0.5000 time: 0.1180s\n",
            "tensor(0.6991, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0131 loss_train: 0.5819 acc_train: 0.6947 loss_val: 0.6910 acc_val: 0.5000 time: 0.1214s\n",
            "tensor(0.6910, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0132 loss_train: 0.5783 acc_train: 0.6947 loss_val: 0.6923 acc_val: 0.5000 time: 0.1268s\n",
            "tensor(0.6923, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0133 loss_train: 0.5768 acc_train: 0.6947 loss_val: 0.6922 acc_val: 0.5000 time: 0.1194s\n",
            "tensor(0.6922, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0134 loss_train: 0.5779 acc_train: 0.6947 loss_val: 0.6879 acc_val: 0.5000 time: 0.1214s\n",
            "tensor(0.6879, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0135 loss_train: 0.5851 acc_train: 0.6947 loss_val: 0.6869 acc_val: 0.5000 time: 0.1189s\n",
            "tensor(0.6869, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0136 loss_train: 0.5762 acc_train: 0.6947 loss_val: 0.6811 acc_val: 0.5000 time: 0.1123s\n",
            "tensor(0.6811, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0137 loss_train: 0.5768 acc_train: 0.6947 loss_val: 0.6971 acc_val: 0.5000 time: 0.1175s\n",
            "tensor(0.6971, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0138 loss_train: 0.5747 acc_train: 0.6947 loss_val: 0.6942 acc_val: 0.5000 time: 0.1100s\n",
            "tensor(0.6942, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0139 loss_train: 0.5733 acc_train: 0.6947 loss_val: 0.6886 acc_val: 0.5000 time: 0.1176s\n",
            "tensor(0.6886, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0140 loss_train: 0.5774 acc_train: 0.6947 loss_val: 0.6845 acc_val: 0.5000 time: 0.1137s\n",
            "tensor(0.6845, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0141 loss_train: 0.5732 acc_train: 0.6947 loss_val: 0.6908 acc_val: 0.5000 time: 0.1220s\n",
            "tensor(0.6908, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0142 loss_train: 0.5751 acc_train: 0.6947 loss_val: 0.6882 acc_val: 0.5000 time: 0.1219s\n",
            "tensor(0.6882, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0143 loss_train: 0.5765 acc_train: 0.6947 loss_val: 0.6767 acc_val: 0.5000 time: 0.1157s\n",
            "tensor(0.6767, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0144 loss_train: 0.5751 acc_train: 0.6947 loss_val: 0.6862 acc_val: 0.5000 time: 0.1121s\n",
            "tensor(0.6862, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0145 loss_train: 0.5755 acc_train: 0.6947 loss_val: 0.6774 acc_val: 0.5000 time: 0.1185s\n",
            "tensor(0.6774, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0146 loss_train: 0.5726 acc_train: 0.6947 loss_val: 0.6758 acc_val: 0.5000 time: 0.1156s\n",
            "tensor(0.6758, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0147 loss_train: 0.5763 acc_train: 0.6947 loss_val: 0.6736 acc_val: 0.5000 time: 0.1149s\n",
            "tensor(0.6736, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0148 loss_train: 0.5695 acc_train: 0.6947 loss_val: 0.6691 acc_val: 0.5000 time: 0.1117s\n",
            "tensor(0.6691, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0149 loss_train: 0.5701 acc_train: 0.6947 loss_val: 0.6796 acc_val: 0.5000 time: 0.1235s\n",
            "tensor(0.6796, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0150 loss_train: 0.5747 acc_train: 0.6947 loss_val: 0.6736 acc_val: 0.5000 time: 0.1205s\n",
            "tensor(0.6736, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0151 loss_train: 0.5678 acc_train: 0.6947 loss_val: 0.6729 acc_val: 0.5000 time: 0.1157s\n",
            "tensor(0.6729, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0152 loss_train: 0.5742 acc_train: 0.6947 loss_val: 0.6731 acc_val: 0.5000 time: 0.1204s\n",
            "tensor(0.6731, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0153 loss_train: 0.5703 acc_train: 0.6947 loss_val: 0.6736 acc_val: 0.5000 time: 0.1277s\n",
            "tensor(0.6736, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0154 loss_train: 0.5646 acc_train: 0.6947 loss_val: 0.6732 acc_val: 0.5000 time: 0.1165s\n",
            "tensor(0.6732, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0155 loss_train: 0.5629 acc_train: 0.6947 loss_val: 0.6637 acc_val: 0.5000 time: 0.1170s\n",
            "tensor(0.6637, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0156 loss_train: 0.5676 acc_train: 0.6947 loss_val: 0.6641 acc_val: 0.5000 time: 0.1126s\n",
            "tensor(0.6641, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0157 loss_train: 0.5682 acc_train: 0.6947 loss_val: 0.6566 acc_val: 0.5000 time: 0.1273s\n",
            "tensor(0.6566, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0158 loss_train: 0.5646 acc_train: 0.6947 loss_val: 0.6596 acc_val: 0.5000 time: 0.1134s\n",
            "tensor(0.6596, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0159 loss_train: 0.5650 acc_train: 0.6947 loss_val: 0.6512 acc_val: 0.5000 time: 0.1146s\n",
            "tensor(0.6512, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0160 loss_train: 0.5665 acc_train: 0.6947 loss_val: 0.6571 acc_val: 0.5000 time: 0.1173s\n",
            "tensor(0.6571, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0161 loss_train: 0.5670 acc_train: 0.6947 loss_val: 0.6551 acc_val: 0.5000 time: 0.1182s\n",
            "tensor(0.6551, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0162 loss_train: 0.5678 acc_train: 0.6947 loss_val: 0.6550 acc_val: 0.5000 time: 0.1168s\n",
            "tensor(0.6550, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0163 loss_train: 0.5612 acc_train: 0.6947 loss_val: 0.6478 acc_val: 0.5000 time: 0.1166s\n",
            "tensor(0.6478, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0164 loss_train: 0.5647 acc_train: 0.6947 loss_val: 0.6547 acc_val: 0.5000 time: 0.1201s\n",
            "tensor(0.6547, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0165 loss_train: 0.5618 acc_train: 0.6947 loss_val: 0.6501 acc_val: 0.5000 time: 0.1247s\n",
            "tensor(0.6501, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0166 loss_train: 0.5593 acc_train: 0.6947 loss_val: 0.6414 acc_val: 0.5000 time: 0.1144s\n",
            "tensor(0.6414, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0167 loss_train: 0.5584 acc_train: 0.6947 loss_val: 0.6365 acc_val: 0.5000 time: 0.1150s\n",
            "tensor(0.6365, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0168 loss_train: 0.5608 acc_train: 0.6947 loss_val: 0.6346 acc_val: 0.5000 time: 0.1128s\n",
            "tensor(0.6346, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0169 loss_train: 0.5581 acc_train: 0.6947 loss_val: 0.6402 acc_val: 0.5000 time: 0.1186s\n",
            "tensor(0.6402, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0170 loss_train: 0.5598 acc_train: 0.6947 loss_val: 0.6387 acc_val: 0.5000 time: 0.1108s\n",
            "tensor(0.6387, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0171 loss_train: 0.5593 acc_train: 0.6947 loss_val: 0.6320 acc_val: 0.5000 time: 0.1333s\n",
            "tensor(0.6320, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0172 loss_train: 0.5587 acc_train: 0.6947 loss_val: 0.6303 acc_val: 0.5000 time: 0.1155s\n",
            "tensor(0.6303, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0173 loss_train: 0.5536 acc_train: 0.6947 loss_val: 0.6279 acc_val: 0.5000 time: 0.1170s\n",
            "tensor(0.6279, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0174 loss_train: 0.5546 acc_train: 0.6947 loss_val: 0.6317 acc_val: 0.5000 time: 0.1206s\n",
            "tensor(0.6317, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0175 loss_train: 0.5543 acc_train: 0.6947 loss_val: 0.6242 acc_val: 0.5000 time: 0.1239s\n",
            "tensor(0.6242, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0176 loss_train: 0.5498 acc_train: 0.6947 loss_val: 0.6245 acc_val: 0.5000 time: 0.1134s\n",
            "tensor(0.6245, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0177 loss_train: 0.5521 acc_train: 0.6947 loss_val: 0.6213 acc_val: 0.5000 time: 0.1218s\n",
            "tensor(0.6213, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0178 loss_train: 0.5520 acc_train: 0.6947 loss_val: 0.6208 acc_val: 0.5000 time: 0.1139s\n",
            "tensor(0.6208, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0179 loss_train: 0.5484 acc_train: 0.6947 loss_val: 0.6192 acc_val: 0.5000 time: 0.1182s\n",
            "tensor(0.6192, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0180 loss_train: 0.5480 acc_train: 0.6947 loss_val: 0.6170 acc_val: 0.5000 time: 0.1229s\n",
            "tensor(0.6170, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0181 loss_train: 0.5472 acc_train: 0.6947 loss_val: 0.6151 acc_val: 0.5000 time: 0.1227s\n",
            "tensor(0.6151, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0182 loss_train: 0.5466 acc_train: 0.6947 loss_val: 0.6072 acc_val: 0.5000 time: 0.1257s\n",
            "tensor(0.6072, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0183 loss_train: 0.5453 acc_train: 0.6947 loss_val: 0.6140 acc_val: 0.5000 time: 0.1169s\n",
            "tensor(0.6140, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0184 loss_train: 0.5425 acc_train: 0.6947 loss_val: 0.6057 acc_val: 0.5000 time: 0.1155s\n",
            "tensor(0.6057, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0185 loss_train: 0.5411 acc_train: 0.6947 loss_val: 0.5985 acc_val: 0.5000 time: 0.1164s\n",
            "tensor(0.5985, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0186 loss_train: 0.5426 acc_train: 0.6947 loss_val: 0.6076 acc_val: 0.5000 time: 0.1133s\n",
            "tensor(0.6076, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0187 loss_train: 0.5378 acc_train: 0.7099 loss_val: 0.6026 acc_val: 0.5714 time: 0.1199s\n",
            "tensor(0.6026, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0188 loss_train: 0.5354 acc_train: 0.7252 loss_val: 0.5993 acc_val: 0.6071 time: 0.1116s\n",
            "tensor(0.5993, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0189 loss_train: 0.5389 acc_train: 0.7328 loss_val: 0.5927 acc_val: 0.6071 time: 0.1157s\n",
            "tensor(0.5927, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0190 loss_train: 0.5371 acc_train: 0.7252 loss_val: 0.5976 acc_val: 0.6071 time: 0.1203s\n",
            "tensor(0.5976, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0191 loss_train: 0.5395 acc_train: 0.7405 loss_val: 0.5929 acc_val: 0.6786 time: 0.1261s\n",
            "tensor(0.5929, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0192 loss_train: 0.5359 acc_train: 0.7405 loss_val: 0.5915 acc_val: 0.7500 time: 0.1300s\n",
            "tensor(0.5915, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0193 loss_train: 0.5404 acc_train: 0.7405 loss_val: 0.5966 acc_val: 0.7143 time: 0.1186s\n",
            "tensor(0.5966, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0194 loss_train: 0.5314 acc_train: 0.7328 loss_val: 0.5896 acc_val: 0.7500 time: 0.1147s\n",
            "tensor(0.5896, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0195 loss_train: 0.5348 acc_train: 0.7328 loss_val: 0.5872 acc_val: 0.7143 time: 0.1204s\n",
            "tensor(0.5872, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0196 loss_train: 0.5355 acc_train: 0.7328 loss_val: 0.5904 acc_val: 0.7143 time: 0.1123s\n",
            "tensor(0.5904, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0197 loss_train: 0.5324 acc_train: 0.7481 loss_val: 0.5876 acc_val: 0.7857 time: 0.1194s\n",
            "tensor(0.5876, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0198 loss_train: 0.5296 acc_train: 0.7405 loss_val: 0.5970 acc_val: 0.7500 time: 0.1209s\n",
            "tensor(0.5970, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0199 loss_train: 0.5297 acc_train: 0.7481 loss_val: 0.5863 acc_val: 0.7857 time: 0.1162s\n",
            "tensor(0.5863, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0200 loss_train: 0.5282 acc_train: 0.7481 loss_val: 0.5893 acc_val: 0.7857 time: 0.1134s\n",
            "tensor(0.5893, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0201 loss_train: 0.5317 acc_train: 0.7634 loss_val: 0.5859 acc_val: 0.8214 time: 0.1181s\n",
            "tensor(0.5859, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0202 loss_train: 0.5306 acc_train: 0.7710 loss_val: 0.5788 acc_val: 0.8214 time: 0.1181s\n",
            "tensor(0.5788, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0203 loss_train: 0.5315 acc_train: 0.7939 loss_val: 0.5849 acc_val: 0.8214 time: 0.1160s\n",
            "tensor(0.5849, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0204 loss_train: 0.5260 acc_train: 0.7786 loss_val: 0.5830 acc_val: 0.7857 time: 0.1141s\n",
            "tensor(0.5830, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0205 loss_train: 0.5281 acc_train: 0.7786 loss_val: 0.5836 acc_val: 0.7500 time: 0.1346s\n",
            "tensor(0.5836, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0206 loss_train: 0.5264 acc_train: 0.7710 loss_val: 0.5891 acc_val: 0.8571 time: 0.1192s\n",
            "tensor(0.5891, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0207 loss_train: 0.5256 acc_train: 0.7710 loss_val: 0.5862 acc_val: 0.8571 time: 0.1198s\n",
            "tensor(0.5862, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0208 loss_train: 0.5249 acc_train: 0.7863 loss_val: 0.5803 acc_val: 0.8571 time: 0.1150s\n",
            "tensor(0.5803, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0209 loss_train: 0.5260 acc_train: 0.7939 loss_val: 0.5844 acc_val: 0.8571 time: 0.1177s\n",
            "tensor(0.5844, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0210 loss_train: 0.5267 acc_train: 0.7863 loss_val: 0.5856 acc_val: 0.8929 time: 0.1152s\n",
            "tensor(0.5856, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0211 loss_train: 0.5244 acc_train: 0.7939 loss_val: 0.5872 acc_val: 0.8929 time: 0.1176s\n",
            "tensor(0.5872, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0212 loss_train: 0.5233 acc_train: 0.8015 loss_val: 0.5830 acc_val: 0.8571 time: 0.1126s\n",
            "tensor(0.5830, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0213 loss_train: 0.5175 acc_train: 0.7939 loss_val: 0.5772 acc_val: 0.8571 time: 0.1165s\n",
            "tensor(0.5772, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0214 loss_train: 0.5201 acc_train: 0.7939 loss_val: 0.5873 acc_val: 0.8571 time: 0.1121s\n",
            "tensor(0.5873, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0215 loss_train: 0.5193 acc_train: 0.8015 loss_val: 0.5776 acc_val: 0.8929 time: 0.1274s\n",
            "tensor(0.5776, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0216 loss_train: 0.5210 acc_train: 0.7863 loss_val: 0.5817 acc_val: 0.8929 time: 0.1203s\n",
            "tensor(0.5817, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0217 loss_train: 0.5166 acc_train: 0.8092 loss_val: 0.5838 acc_val: 0.8929 time: 0.1262s\n",
            "tensor(0.5838, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0218 loss_train: 0.5205 acc_train: 0.7939 loss_val: 0.5861 acc_val: 0.8929 time: 0.1194s\n",
            "tensor(0.5861, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0219 loss_train: 0.5181 acc_train: 0.8015 loss_val: 0.5800 acc_val: 0.8929 time: 0.1237s\n",
            "tensor(0.5800, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0220 loss_train: 0.5179 acc_train: 0.8321 loss_val: 0.5882 acc_val: 0.8929 time: 0.1111s\n",
            "tensor(0.5882, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0221 loss_train: 0.5186 acc_train: 0.8015 loss_val: 0.5882 acc_val: 0.8929 time: 0.1160s\n",
            "tensor(0.5882, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0222 loss_train: 0.5155 acc_train: 0.8168 loss_val: 0.5789 acc_val: 0.8929 time: 0.1121s\n",
            "tensor(0.5789, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0223 loss_train: 0.5156 acc_train: 0.8092 loss_val: 0.5860 acc_val: 0.8929 time: 0.1282s\n",
            "tensor(0.5860, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0224 loss_train: 0.5161 acc_train: 0.8092 loss_val: 0.5880 acc_val: 0.8929 time: 0.1136s\n",
            "tensor(0.5880, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0225 loss_train: 0.5165 acc_train: 0.8092 loss_val: 0.5859 acc_val: 0.8929 time: 0.1196s\n",
            "tensor(0.5859, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0226 loss_train: 0.5151 acc_train: 0.8092 loss_val: 0.5827 acc_val: 0.8929 time: 0.1170s\n",
            "tensor(0.5827, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0227 loss_train: 0.5150 acc_train: 0.8092 loss_val: 0.5800 acc_val: 0.8929 time: 0.1258s\n",
            "tensor(0.5800, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0228 loss_train: 0.5118 acc_train: 0.8244 loss_val: 0.5882 acc_val: 0.8929 time: 0.1136s\n",
            "tensor(0.5882, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0229 loss_train: 0.5139 acc_train: 0.8244 loss_val: 0.5899 acc_val: 0.8571 time: 0.1173s\n",
            "tensor(0.5899, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0230 loss_train: 0.5117 acc_train: 0.8244 loss_val: 0.5874 acc_val: 0.8929 time: 0.1286s\n",
            "tensor(0.5874, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0231 loss_train: 0.5115 acc_train: 0.8168 loss_val: 0.5869 acc_val: 0.8929 time: 0.1285s\n",
            "tensor(0.5869, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0232 loss_train: 0.5132 acc_train: 0.8244 loss_val: 0.5856 acc_val: 0.8929 time: 0.1131s\n",
            "tensor(0.5856, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0233 loss_train: 0.5121 acc_train: 0.8321 loss_val: 0.5823 acc_val: 0.8929 time: 0.1166s\n",
            "tensor(0.5823, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0234 loss_train: 0.5105 acc_train: 0.8244 loss_val: 0.5854 acc_val: 0.8929 time: 0.1131s\n",
            "tensor(0.5854, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0235 loss_train: 0.5076 acc_train: 0.8244 loss_val: 0.5757 acc_val: 0.8929 time: 0.1182s\n",
            "tensor(0.5757, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0236 loss_train: 0.5082 acc_train: 0.8397 loss_val: 0.5870 acc_val: 0.8929 time: 0.1146s\n",
            "tensor(0.5870, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0237 loss_train: 0.5084 acc_train: 0.8321 loss_val: 0.5823 acc_val: 0.8929 time: 0.1159s\n",
            "tensor(0.5823, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0238 loss_train: 0.5087 acc_train: 0.8244 loss_val: 0.5831 acc_val: 0.8929 time: 0.1201s\n",
            "tensor(0.5831, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0239 loss_train: 0.5079 acc_train: 0.8168 loss_val: 0.5851 acc_val: 0.8929 time: 0.1268s\n",
            "tensor(0.5851, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0240 loss_train: 0.5121 acc_train: 0.8244 loss_val: 0.5839 acc_val: 0.8929 time: 0.1196s\n",
            "tensor(0.5839, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0241 loss_train: 0.5048 acc_train: 0.8244 loss_val: 0.5851 acc_val: 0.8929 time: 0.1183s\n",
            "tensor(0.5851, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0242 loss_train: 0.5073 acc_train: 0.8397 loss_val: 0.5842 acc_val: 0.8929 time: 0.1138s\n",
            "tensor(0.5842, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0243 loss_train: 0.5076 acc_train: 0.8397 loss_val: 0.5834 acc_val: 0.8929 time: 0.1165s\n",
            "tensor(0.5834, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0244 loss_train: 0.5076 acc_train: 0.8397 loss_val: 0.5916 acc_val: 0.8929 time: 0.1112s\n",
            "tensor(0.5916, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0245 loss_train: 0.5058 acc_train: 0.8473 loss_val: 0.5744 acc_val: 0.8929 time: 0.1185s\n",
            "tensor(0.5744, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0246 loss_train: 0.5067 acc_train: 0.8321 loss_val: 0.5773 acc_val: 0.8929 time: 0.1171s\n",
            "tensor(0.5773, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0247 loss_train: 0.5047 acc_train: 0.8397 loss_val: 0.5786 acc_val: 0.8929 time: 0.1314s\n",
            "tensor(0.5786, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0248 loss_train: 0.5081 acc_train: 0.8321 loss_val: 0.5826 acc_val: 0.8929 time: 0.1112s\n",
            "tensor(0.5826, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0249 loss_train: 0.5071 acc_train: 0.8321 loss_val: 0.5824 acc_val: 0.8929 time: 0.1165s\n",
            "tensor(0.5824, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0250 loss_train: 0.5051 acc_train: 0.8321 loss_val: 0.5803 acc_val: 0.8929 time: 0.1128s\n",
            "tensor(0.5803, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0251 loss_train: 0.5063 acc_train: 0.8473 loss_val: 0.5763 acc_val: 0.8929 time: 0.1209s\n",
            "tensor(0.5763, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0252 loss_train: 0.5030 acc_train: 0.8473 loss_val: 0.5835 acc_val: 0.8929 time: 0.1162s\n",
            "tensor(0.5835, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0253 loss_train: 0.5055 acc_train: 0.8473 loss_val: 0.5775 acc_val: 0.8929 time: 0.1196s\n",
            "tensor(0.5775, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0254 loss_train: 0.5068 acc_train: 0.8473 loss_val: 0.5809 acc_val: 0.8929 time: 0.1126s\n",
            "tensor(0.5809, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0255 loss_train: 0.5039 acc_train: 0.8473 loss_val: 0.5787 acc_val: 0.8929 time: 0.1169s\n",
            "tensor(0.5787, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0256 loss_train: 0.4991 acc_train: 0.8397 loss_val: 0.5829 acc_val: 0.8929 time: 0.1301s\n",
            "tensor(0.5829, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0257 loss_train: 0.5070 acc_train: 0.8397 loss_val: 0.5759 acc_val: 0.8929 time: 0.1231s\n",
            "tensor(0.5759, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0258 loss_train: 0.5058 acc_train: 0.8321 loss_val: 0.5754 acc_val: 0.8929 time: 0.1177s\n",
            "tensor(0.5754, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0259 loss_train: 0.5038 acc_train: 0.8397 loss_val: 0.5764 acc_val: 0.8929 time: 0.1176s\n",
            "tensor(0.5764, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0260 loss_train: 0.5043 acc_train: 0.8397 loss_val: 0.5825 acc_val: 0.8929 time: 0.1128s\n",
            "tensor(0.5825, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0261 loss_train: 0.5015 acc_train: 0.8397 loss_val: 0.5809 acc_val: 0.8929 time: 0.1141s\n",
            "tensor(0.5809, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0262 loss_train: 0.5034 acc_train: 0.8397 loss_val: 0.5831 acc_val: 0.8929 time: 0.1141s\n",
            "tensor(0.5831, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0263 loss_train: 0.5034 acc_train: 0.8473 loss_val: 0.5830 acc_val: 0.8929 time: 0.1144s\n",
            "tensor(0.5830, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0264 loss_train: 0.5053 acc_train: 0.8473 loss_val: 0.5792 acc_val: 0.8929 time: 0.1178s\n",
            "tensor(0.5792, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0265 loss_train: 0.5021 acc_train: 0.8321 loss_val: 0.5844 acc_val: 0.8929 time: 0.1158s\n",
            "tensor(0.5844, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0266 loss_train: 0.5039 acc_train: 0.8473 loss_val: 0.5788 acc_val: 0.8929 time: 0.1169s\n",
            "tensor(0.5788, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0267 loss_train: 0.5031 acc_train: 0.8473 loss_val: 0.5823 acc_val: 0.8929 time: 0.1289s\n",
            "tensor(0.5823, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0268 loss_train: 0.5032 acc_train: 0.8397 loss_val: 0.5761 acc_val: 0.8929 time: 0.1248s\n",
            "tensor(0.5761, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0269 loss_train: 0.5035 acc_train: 0.8473 loss_val: 0.5749 acc_val: 0.8929 time: 0.1173s\n",
            "tensor(0.5749, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0270 loss_train: 0.5002 acc_train: 0.8473 loss_val: 0.5796 acc_val: 0.8929 time: 0.1230s\n",
            "tensor(0.5796, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0271 loss_train: 0.5021 acc_train: 0.8397 loss_val: 0.5779 acc_val: 0.8929 time: 0.1175s\n",
            "tensor(0.5779, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0272 loss_train: 0.5055 acc_train: 0.8473 loss_val: 0.5756 acc_val: 0.8929 time: 0.1228s\n",
            "tensor(0.5756, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0273 loss_train: 0.5012 acc_train: 0.8473 loss_val: 0.5799 acc_val: 0.8929 time: 0.1165s\n",
            "tensor(0.5799, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0274 loss_train: 0.5015 acc_train: 0.8473 loss_val: 0.5837 acc_val: 0.8571 time: 0.1139s\n",
            "tensor(0.5837, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0275 loss_train: 0.5002 acc_train: 0.8397 loss_val: 0.5762 acc_val: 0.8929 time: 0.1170s\n",
            "tensor(0.5762, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0276 loss_train: 0.5008 acc_train: 0.8473 loss_val: 0.5809 acc_val: 0.8929 time: 0.1131s\n",
            "tensor(0.5809, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0277 loss_train: 0.4975 acc_train: 0.8473 loss_val: 0.5809 acc_val: 0.8929 time: 0.1211s\n",
            "tensor(0.5809, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0278 loss_train: 0.4995 acc_train: 0.8473 loss_val: 0.5810 acc_val: 0.8929 time: 0.1141s\n",
            "tensor(0.5810, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0279 loss_train: 0.4997 acc_train: 0.8397 loss_val: 0.5805 acc_val: 0.8929 time: 0.1193s\n",
            "tensor(0.5805, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0280 loss_train: 0.5035 acc_train: 0.8473 loss_val: 0.5813 acc_val: 0.8929 time: 0.1375s\n",
            "tensor(0.5813, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0281 loss_train: 0.5008 acc_train: 0.8397 loss_val: 0.5764 acc_val: 0.8929 time: 0.1204s\n",
            "tensor(0.5764, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0282 loss_train: 0.4954 acc_train: 0.8397 loss_val: 0.5833 acc_val: 0.8929 time: 0.1214s\n",
            "tensor(0.5833, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0283 loss_train: 0.4990 acc_train: 0.8397 loss_val: 0.5741 acc_val: 0.8929 time: 0.1281s\n",
            "tensor(0.5741, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0284 loss_train: 0.5012 acc_train: 0.8473 loss_val: 0.5834 acc_val: 0.8929 time: 0.1142s\n",
            "tensor(0.5834, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0285 loss_train: 0.4976 acc_train: 0.8473 loss_val: 0.5815 acc_val: 0.8929 time: 0.1229s\n",
            "tensor(0.5815, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0286 loss_train: 0.4989 acc_train: 0.8473 loss_val: 0.5811 acc_val: 0.8929 time: 0.1161s\n",
            "tensor(0.5811, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0287 loss_train: 0.4971 acc_train: 0.8473 loss_val: 0.5795 acc_val: 0.8929 time: 0.1279s\n",
            "tensor(0.5795, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0288 loss_train: 0.5011 acc_train: 0.8397 loss_val: 0.5782 acc_val: 0.8929 time: 0.1265s\n",
            "tensor(0.5782, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0289 loss_train: 0.4975 acc_train: 0.8397 loss_val: 0.5846 acc_val: 0.8571 time: 0.1176s\n",
            "tensor(0.5846, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0290 loss_train: 0.5021 acc_train: 0.8397 loss_val: 0.5879 acc_val: 0.8929 time: 0.1128s\n",
            "tensor(0.5879, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0291 loss_train: 0.4963 acc_train: 0.8473 loss_val: 0.5880 acc_val: 0.8571 time: 0.1237s\n",
            "tensor(0.5880, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0292 loss_train: 0.4966 acc_train: 0.8397 loss_val: 0.5868 acc_val: 0.8929 time: 0.1119s\n",
            "tensor(0.5868, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0293 loss_train: 0.4950 acc_train: 0.8397 loss_val: 0.5774 acc_val: 0.8929 time: 0.1159s\n",
            "tensor(0.5774, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0294 loss_train: 0.4971 acc_train: 0.8473 loss_val: 0.5756 acc_val: 0.8929 time: 0.1283s\n",
            "tensor(0.5756, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0295 loss_train: 0.4974 acc_train: 0.8397 loss_val: 0.5825 acc_val: 0.8929 time: 0.1152s\n",
            "tensor(0.5825, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0296 loss_train: 0.4961 acc_train: 0.8473 loss_val: 0.5794 acc_val: 0.8929 time: 0.1202s\n",
            "tensor(0.5794, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0297 loss_train: 0.4947 acc_train: 0.8473 loss_val: 0.5810 acc_val: 0.8929 time: 0.1219s\n",
            "tensor(0.5810, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0298 loss_train: 0.4955 acc_train: 0.8473 loss_val: 0.5710 acc_val: 0.8929 time: 0.1135s\n",
            "tensor(0.5710, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0299 loss_train: 0.4979 acc_train: 0.8397 loss_val: 0.5820 acc_val: 0.8571 time: 0.1196s\n",
            "tensor(0.5820, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0300 loss_train: 0.4984 acc_train: 0.8397 loss_val: 0.5837 acc_val: 0.8929 time: 0.1119s\n",
            "tensor(0.5837, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0301 loss_train: 0.4967 acc_train: 0.8397 loss_val: 0.5821 acc_val: 0.8929 time: 0.1197s\n",
            "tensor(0.5821, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0302 loss_train: 0.4965 acc_train: 0.8473 loss_val: 0.5843 acc_val: 0.8571 time: 0.1141s\n",
            "tensor(0.5843, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0303 loss_train: 0.4981 acc_train: 0.8397 loss_val: 0.5872 acc_val: 0.8571 time: 0.1168s\n",
            "tensor(0.5872, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0304 loss_train: 0.4978 acc_train: 0.8550 loss_val: 0.5925 acc_val: 0.8571 time: 0.1168s\n",
            "tensor(0.5925, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0305 loss_train: 0.4971 acc_train: 0.8550 loss_val: 0.5816 acc_val: 0.8571 time: 0.1261s\n",
            "tensor(0.5816, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0306 loss_train: 0.4934 acc_train: 0.8550 loss_val: 0.5815 acc_val: 0.8571 time: 0.1125s\n",
            "tensor(0.5815, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0307 loss_train: 0.4945 acc_train: 0.8473 loss_val: 0.5758 acc_val: 0.8929 time: 0.1154s\n",
            "tensor(0.5758, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0308 loss_train: 0.4941 acc_train: 0.8397 loss_val: 0.5720 acc_val: 0.8929 time: 0.1176s\n",
            "tensor(0.5720, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0309 loss_train: 0.4936 acc_train: 0.8397 loss_val: 0.5728 acc_val: 0.8929 time: 0.1161s\n",
            "tensor(0.5728, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0310 loss_train: 0.4921 acc_train: 0.8397 loss_val: 0.5759 acc_val: 0.8929 time: 0.1133s\n",
            "tensor(0.5759, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0311 loss_train: 0.4973 acc_train: 0.8397 loss_val: 0.5821 acc_val: 0.8929 time: 0.1156s\n",
            "tensor(0.5821, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0312 loss_train: 0.4921 acc_train: 0.8550 loss_val: 0.5799 acc_val: 0.8571 time: 0.1123s\n",
            "tensor(0.5799, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0313 loss_train: 0.4944 acc_train: 0.8397 loss_val: 0.5837 acc_val: 0.8571 time: 0.1354s\n",
            "tensor(0.5837, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0314 loss_train: 0.4976 acc_train: 0.8550 loss_val: 0.5813 acc_val: 0.8571 time: 0.1174s\n",
            "tensor(0.5813, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0315 loss_train: 0.4914 acc_train: 0.8626 loss_val: 0.5818 acc_val: 0.8571 time: 0.1219s\n",
            "tensor(0.5818, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0316 loss_train: 0.4941 acc_train: 0.8550 loss_val: 0.5801 acc_val: 0.8571 time: 0.1141s\n",
            "tensor(0.5801, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0317 loss_train: 0.4941 acc_train: 0.8550 loss_val: 0.5762 acc_val: 0.8571 time: 0.1155s\n",
            "tensor(0.5762, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0318 loss_train: 0.4912 acc_train: 0.8473 loss_val: 0.5728 acc_val: 0.8571 time: 0.1110s\n",
            "tensor(0.5728, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0319 loss_train: 0.4922 acc_train: 0.8550 loss_val: 0.5733 acc_val: 0.8571 time: 0.1154s\n",
            "tensor(0.5733, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0320 loss_train: 0.4874 acc_train: 0.8550 loss_val: 0.5707 acc_val: 0.8571 time: 0.1147s\n",
            "tensor(0.5707, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0321 loss_train: 0.4911 acc_train: 0.8397 loss_val: 0.5686 acc_val: 0.8571 time: 0.1220s\n",
            "tensor(0.5686, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0322 loss_train: 0.4893 acc_train: 0.8473 loss_val: 0.5692 acc_val: 0.8571 time: 0.1164s\n",
            "tensor(0.5692, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0323 loss_train: 0.4891 acc_train: 0.8550 loss_val: 0.5794 acc_val: 0.8571 time: 0.1234s\n",
            "tensor(0.5794, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0324 loss_train: 0.4899 acc_train: 0.8626 loss_val: 0.5701 acc_val: 0.8571 time: 0.1315s\n",
            "tensor(0.5701, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0325 loss_train: 0.4898 acc_train: 0.8626 loss_val: 0.5681 acc_val: 0.8571 time: 0.1257s\n",
            "tensor(0.5681, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0326 loss_train: 0.4883 acc_train: 0.8626 loss_val: 0.5648 acc_val: 0.8571 time: 0.1221s\n",
            "tensor(0.5648, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0327 loss_train: 0.4894 acc_train: 0.8626 loss_val: 0.5630 acc_val: 0.8571 time: 0.1198s\n",
            "tensor(0.5630, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0328 loss_train: 0.4848 acc_train: 0.8473 loss_val: 0.5669 acc_val: 0.8571 time: 0.1172s\n",
            "tensor(0.5669, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0329 loss_train: 0.4826 acc_train: 0.8550 loss_val: 0.5591 acc_val: 0.8571 time: 0.1241s\n",
            "tensor(0.5591, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0330 loss_train: 0.4800 acc_train: 0.8626 loss_val: 0.5590 acc_val: 0.8571 time: 0.1148s\n",
            "tensor(0.5590, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0331 loss_train: 0.4832 acc_train: 0.8550 loss_val: 0.5590 acc_val: 0.8571 time: 0.1273s\n",
            "tensor(0.5590, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0332 loss_train: 0.4851 acc_train: 0.8473 loss_val: 0.5574 acc_val: 0.8571 time: 0.1256s\n",
            "tensor(0.5574, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0333 loss_train: 0.4823 acc_train: 0.8550 loss_val: 0.5595 acc_val: 0.8571 time: 0.1157s\n",
            "tensor(0.5595, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0334 loss_train: 0.4795 acc_train: 0.8626 loss_val: 0.5638 acc_val: 0.8214 time: 0.1124s\n",
            "tensor(0.5638, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0335 loss_train: 0.4796 acc_train: 0.8550 loss_val: 0.5593 acc_val: 0.8571 time: 0.1251s\n",
            "tensor(0.5593, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0336 loss_train: 0.4752 acc_train: 0.8626 loss_val: 0.5579 acc_val: 0.8571 time: 0.1255s\n",
            "tensor(0.5579, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0337 loss_train: 0.4795 acc_train: 0.8473 loss_val: 0.5628 acc_val: 0.8571 time: 0.1333s\n",
            "tensor(0.5628, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0338 loss_train: 0.4788 acc_train: 0.8550 loss_val: 0.5481 acc_val: 0.8214 time: 0.1145s\n",
            "tensor(0.5481, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0339 loss_train: 0.4773 acc_train: 0.8550 loss_val: 0.5528 acc_val: 0.8571 time: 0.1239s\n",
            "tensor(0.5528, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0340 loss_train: 0.4768 acc_train: 0.8626 loss_val: 0.5349 acc_val: 0.8571 time: 0.1160s\n",
            "tensor(0.5349, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0341 loss_train: 0.4784 acc_train: 0.8473 loss_val: 0.5415 acc_val: 0.8571 time: 0.1178s\n",
            "tensor(0.5415, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0342 loss_train: 0.4747 acc_train: 0.8626 loss_val: 0.5390 acc_val: 0.8571 time: 0.1164s\n",
            "tensor(0.5390, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0343 loss_train: 0.4707 acc_train: 0.8550 loss_val: 0.5318 acc_val: 0.8571 time: 0.1256s\n",
            "tensor(0.5318, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0344 loss_train: 0.4736 acc_train: 0.8550 loss_val: 0.5323 acc_val: 0.8571 time: 0.1201s\n",
            "tensor(0.5323, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0345 loss_train: 0.4724 acc_train: 0.8550 loss_val: 0.5441 acc_val: 0.8571 time: 0.1212s\n",
            "tensor(0.5441, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0346 loss_train: 0.4771 acc_train: 0.8550 loss_val: 0.5416 acc_val: 0.8571 time: 0.1173s\n",
            "tensor(0.5416, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0347 loss_train: 0.4681 acc_train: 0.8626 loss_val: 0.5404 acc_val: 0.8214 time: 0.1243s\n",
            "tensor(0.5404, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0348 loss_train: 0.4684 acc_train: 0.8550 loss_val: 0.5540 acc_val: 0.7857 time: 0.1132s\n",
            "tensor(0.5540, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0349 loss_train: 0.4608 acc_train: 0.8702 loss_val: 0.5512 acc_val: 0.7857 time: 0.1203s\n",
            "tensor(0.5512, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0350 loss_train: 0.4678 acc_train: 0.8473 loss_val: 0.5497 acc_val: 0.8571 time: 0.1176s\n",
            "tensor(0.5497, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0351 loss_train: 0.4685 acc_train: 0.8550 loss_val: 0.5297 acc_val: 0.8929 time: 0.1154s\n",
            "tensor(0.5297, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0352 loss_train: 0.4738 acc_train: 0.8473 loss_val: 0.5122 acc_val: 0.8571 time: 0.1161s\n",
            "tensor(0.5122, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0353 loss_train: 0.4644 acc_train: 0.8550 loss_val: 0.5351 acc_val: 0.8214 time: 0.1203s\n",
            "tensor(0.5351, grad_fn=<NllLossBackward>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0354 loss_train: 0.4692 acc_train: 0.8626 loss_val: 0.5277 acc_val: 0.8214 time: 0.1220s\n",
            "tensor(0.5277, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0355 loss_train: 0.4601 acc_train: 0.8702 loss_val: 0.5222 acc_val: 0.8214 time: 0.1177s\n",
            "tensor(0.5222, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0356 loss_train: 0.4670 acc_train: 0.8626 loss_val: 0.5171 acc_val: 0.8214 time: 0.1203s\n",
            "tensor(0.5171, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0357 loss_train: 0.4729 acc_train: 0.8626 loss_val: 0.5250 acc_val: 0.8214 time: 0.1260s\n",
            "tensor(0.5250, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0358 loss_train: 0.4641 acc_train: 0.8473 loss_val: 0.5230 acc_val: 0.8214 time: 0.1246s\n",
            "tensor(0.5230, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0359 loss_train: 0.4541 acc_train: 0.8779 loss_val: 0.5355 acc_val: 0.8571 time: 0.1205s\n",
            "tensor(0.5355, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0360 loss_train: 0.4615 acc_train: 0.8626 loss_val: 0.5169 acc_val: 0.8929 time: 0.1214s\n",
            "tensor(0.5169, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0361 loss_train: 0.4589 acc_train: 0.8550 loss_val: 0.4989 acc_val: 0.8571 time: 0.1166s\n",
            "tensor(0.4989, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0362 loss_train: 0.4533 acc_train: 0.8702 loss_val: 0.5075 acc_val: 0.8214 time: 0.1200s\n",
            "tensor(0.5075, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0363 loss_train: 0.4550 acc_train: 0.8626 loss_val: 0.4869 acc_val: 0.8214 time: 0.1170s\n",
            "tensor(0.4869, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0364 loss_train: 0.4698 acc_train: 0.8550 loss_val: 0.5121 acc_val: 0.7857 time: 0.1137s\n",
            "tensor(0.5121, grad_fn=<NllLossBackward>)\n",
            "Epoch: 0365 loss_train: 0.4578 acc_train: 0.8473 loss_val: 0.4936 acc_val: 0.8571 time: 0.1167s\n",
            "tensor(0.4936, grad_fn=<NllLossBackward>)\n",
            "Optimization Finished!\n",
            "Total time elapsed: 45.7335s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zn750VouPDLt",
        "outputId": "724f1be3-f69a-4c4a-a0dc-286a038dade5"
      },
      "source": [
        "output = None\r\n",
        "for i in idx_test:\r\n",
        "  if output is None:\r\n",
        "    output = model(features_list[i], adj_list[i], idx_map)\r\n",
        "  else:\r\n",
        "    output = torch.vstack((output, model(features_list[i], adj_list[i], idx_map)))\r\n",
        "loss_test = F.cross_entropy(output, labels[idx_test])\r\n",
        "acc_test = accuracy(output, labels[idx_test])\r\n",
        "print(loss_test)\r\n",
        "print(acc_test)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.5385, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7586, dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CWggHMLD-Lm"
      },
      "source": [
        "PATH = \"/content/ckpt\"\r\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0soKTmYNKft"
      },
      "source": [
        "# Graph generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T6KDrYxJdDU"
      },
      "source": [
        "<h2> Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D342EJmwFdZ5"
      },
      "source": [
        "from torch.nn.modules.module import Module\r\n",
        "from torch.nn import Linear\r\n",
        "from torch.nn import ReLU6\r\n",
        "from torch.nn import Sequential\r\n",
        "import random\r\n",
        "\r\n",
        "import copy\r\n",
        "\r\n",
        "MAX_NUM_NODES = 28 # for mutag\r\n",
        "random.seed(200)\r\n",
        "\r\n",
        "# import GCN (later when using python file)\r\n",
        "\r\n",
        "class Generator(Module):\r\n",
        "    def __init__(self, \r\n",
        "                 C: list,\r\n",
        "                 c=0,\r\n",
        "                 hyp1=1, \r\n",
        "                 hyp2=2, \r\n",
        "                 start=None,\r\n",
        "                 nfeat=7,\r\n",
        "                 dropout=0.1):\r\n",
        "        \"\"\" \r\n",
        "        :param C: Candidate set of nodes (list)\r\n",
        "        :param start: Starting node (defaults to randomised node)\r\n",
        "        \"\"\"\r\n",
        "        super(Generator, self).__init__()\r\n",
        "\r\n",
        "        self.nfeat = nfeat\r\n",
        "        self.dropout = dropout\r\n",
        "        self.c = c\r\n",
        "\r\n",
        "        self.fc = Linear(nfeat, 8)\r\n",
        "        self.gc1 = GraphConvolution(8, 16)\r\n",
        "        self.gc2 = GraphConvolution(16, 24)\r\n",
        "        self.gc3 = GraphConvolution(24, 32)\r\n",
        "\r\n",
        "        # MLP1\r\n",
        "        # 2 FC layers with hidden dimension 16\r\n",
        "        self.mlp1 = Sequential(Linear(32, 16),\r\n",
        "                               Linear(16, 1))\r\n",
        "\r\n",
        "        # MLP2\r\n",
        "        # 2 FC layers with hidden dimension 24\r\n",
        "        self.mlp2 = Sequential(Linear(64, 24),\r\n",
        "                               Linear(24, 1))\r\n",
        "\r\n",
        "        # Hyperparameters\r\n",
        "        self.hyp1 = hyp1\r\n",
        "        self.hyp2 = hyp2\r\n",
        "        self.candidate_set = C\r\n",
        "        \r\n",
        "        # Default starting node (if any)\r\n",
        "        if start is not None:\r\n",
        "          self.start = start\r\n",
        "          self.random_start = False\r\n",
        "        else:\r\n",
        "          self.start = random.choice(np.arange(0, len(self.candidate_set)))\r\n",
        "          self.random_start = True\r\n",
        "\r\n",
        "        # Load GCN for calculating reward\r\n",
        "        self.model = GCN(nfeat=features_list[0].shape[1],\r\n",
        "                         nclass=labels.max().item() + 1,\r\n",
        "                         dropout=args.dropout)\r\n",
        "        \r\n",
        "        self.model.load_state_dict(torch.load(PATH))\r\n",
        "        for param in self.model.parameters():\r\n",
        "          param.requires_grad = False\r\n",
        "\r\n",
        "        self.reset_graph()\r\n",
        "        \r\n",
        "    def reset_graph(self):\r\n",
        "        \"\"\"\r\n",
        "        Reset g.G to default graph with only start node\r\n",
        "        \"\"\"\r\n",
        "        if self.random_start == True:\r\n",
        "            self.start = random.choice(np.arange(0, len(self.candidate_set)))\r\n",
        "\r\n",
        "        mask_start = torch.BoolTensor([False if i == 0 else True for i in range(MAX_NUM_NODES + len(self.candidate_set))])\r\n",
        "        \r\n",
        "        adj = torch.zeros((MAX_NUM_NODES + len(self.candidate_set), MAX_NUM_NODES + len(self.candidate_set)), dtype=torch.float32)\r\n",
        "\r\n",
        "        feat = torch.zeros((MAX_NUM_NODES + len(self.candidate_set), len(self.candidate_set)), dtype=torch.float32)\r\n",
        "        feat[0, self.start] = 1\r\n",
        "        feat[np.arange(-len(self.candidate_set), 0), np.arange(0, len(self.candidate_set))] = 1\r\n",
        "\r\n",
        "        degrees = torch.zeros(MAX_NUM_NODES)\r\n",
        "\r\n",
        "        self.G = {'adj': adj, 'feat': feat, 'degrees': degrees, 'num_nodes': 1, 'mask_start': mask_start}\r\n",
        "\r\n",
        "    def calculate_loss(self, Rt, p_start, a_start, p_end, a_end, G_t_1):\r\n",
        "        \"\"\"\r\n",
        "        Calculated from cross entropy loss (Lce) and reward function (Rt)\r\n",
        "        where loss = -Rt*(Lce_start + Lce_end)\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "        Lce_start = F.cross_entropy(torch.reshape(p_start, (1, 35)), a_start.unsqueeze(0))\r\n",
        "        Lce_end = F.cross_entropy(torch.reshape(p_end, (1, 35)), a_end.unsqueeze(0))\r\n",
        "\r\n",
        "        return -Rt*(Lce_start + Lce_end)\r\n",
        "\r\n",
        "    def calculate_reward(self, G_t_1):\r\n",
        "        \"\"\"\r\n",
        "        Rtr     Calculated from graph rules to encourage generated graphs to be valid\r\n",
        "                1. Only one edge to be added between any two nodes\r\n",
        "                2. Generated graph cannot contain more nodes than predefined maximum node number\r\n",
        "                3. (For chemical) Degree cannot exceed valency\r\n",
        "                If generated graph violates graph rule, Rtr = -1\r\n",
        "\r\n",
        "        Rtf     Feedback from trained model\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "        rtr = self.check_graph_rules(G_t_1)\r\n",
        "\r\n",
        "        rtf = self.calculate_reward_feedback(G_t_1)\r\n",
        "        rtf_sum = 0\r\n",
        "        for m in range(rollout):\r\n",
        "            p_start, a_start, p_end, a_end, G_t_1 = self.forward(G_t_1)\r\n",
        "            rtf_sum += self.calculate_reward_feedback(G_t_1)\r\n",
        "        rtf = rtf + rtf_sum * self.hyp1 / rollout\r\n",
        "\r\n",
        "        return rtf + self.hyp2 * rtr\r\n",
        "\r\n",
        "    def calculate_reward_feedback(self, G_t_1):\r\n",
        "        \"\"\"\r\n",
        "        p(f(G_t_1) = c) - 1/l\r\n",
        "        where l denotes number of possible classes for f\r\n",
        "        \"\"\"\r\n",
        "        f = self.model(G_t_1['feat'], G_t_1['adj'], None)\r\n",
        "        return f[self.c] - 1/len(f)\r\n",
        "\r\n",
        "    def check_graph_rules(self, G_t_1):\r\n",
        "        \"\"\"\r\n",
        "        For mutag, node degrees cannot exceed valency\r\n",
        "        \"\"\"\r\n",
        "        idx = 0\r\n",
        "\r\n",
        "        for d in G_t_1['degrees']:\r\n",
        "          if d is not 0:\r\n",
        "            node_id = torch.argmax(G_t_1['feat'][idx]) # Eg. [0, 1, 0, 0] -> 1\r\n",
        "            node = self.candidate_set[node_id]  # Eg ['C.4', 'F.2', 'Br.7'][1] = 'F.2'\r\n",
        "            max_valency = int(node.split('.')[1]) # Eg. C.4 -> ['C', '4'] -> 4\r\n",
        "\r\n",
        "            # If any node degree exceeds its valency, return -1\r\n",
        "            if max_valency < d:\r\n",
        "                return -1\r\n",
        "\r\n",
        "        return 0\r\n",
        "        \r\n",
        "    def forward(self, G_in):\r\n",
        "        G = copy.deepcopy(G_in)\r\n",
        "\r\n",
        "        x = G['feat'].detach().clone()\r\n",
        "        adj = G['adj'].detach().clone()\r\n",
        "\r\n",
        "        x = F.relu6(self.fc(x))\r\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\r\n",
        "        x = F.relu6(self.gc1(x, adj))\r\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\r\n",
        "        x = F.relu6(self.gc2(x, adj))\r\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\r\n",
        "        x = F.relu6(self.gc3(x, adj))\r\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\r\n",
        "\r\n",
        "        p_start = self.mlp1(x)\r\n",
        "        p_start = p_start.masked_fill(G['mask_start'].unsqueeze(1), 0)\r\n",
        "        p_start = F.softmax(p_start, dim=0)\r\n",
        "        a_start_idx = torch.argmax(p_start.masked_fill(G['mask_start'].unsqueeze(1), -1))\r\n",
        "        \r\n",
        "        # broadcast\r\n",
        "        x1, x2 = torch.broadcast_tensors(x, x[a_start_idx])\r\n",
        "        x = torch.cat((x1, x2), 1) # cat increases dim from 32 to 64\r\n",
        "\r\n",
        "        mask_end = torch.BoolTensor([True for i in range(MAX_NUM_NODES + len(self.candidate_set))])\r\n",
        "        mask_end[MAX_NUM_NODES:] = False\r\n",
        "        mask_end[:G['num_nodes']] = False\r\n",
        "        mask_end[a_start_idx] = True\r\n",
        "\r\n",
        "        p_end = self.mlp2(x)\r\n",
        "        p_end = p_end.masked_fill(mask_end.unsqueeze(1), 0)\r\n",
        "        p_end = F.softmax(p_end, dim=0)\r\n",
        "        a_end_idx = torch.argmax(p_end.masked_fill(mask_end.unsqueeze(1), -1))\r\n",
        "\r\n",
        "        # Return new G\r\n",
        "        # If a_end_idx is not masked, node exists in graph, no new node added\r\n",
        "        if G['mask_start'][a_end_idx] == False:\r\n",
        "            G['adj'][a_end_idx][a_start_idx] += 1\r\n",
        "            G['adj'][a_start_idx][a_end_idx] += 1\r\n",
        "            \r\n",
        "            # Update degrees\r\n",
        "            G['degrees'][a_start_idx] += 1\r\n",
        "            G['degrees'][G['num_nodes']] += 1\r\n",
        "        else:\r\n",
        "            # Add node\r\n",
        "            G['feat'][G['num_nodes']] = G['feat'][a_end_idx]\r\n",
        "            # Add edge\r\n",
        "            G['adj'][G['num_nodes']][a_start_idx] += 1\r\n",
        "            G['adj'][a_start_idx][G['num_nodes']] += 1\r\n",
        "            # Update degrees\r\n",
        "            G['degrees'][a_start_idx] += 1\r\n",
        "            G['degrees'][G['num_nodes']] += 1\r\n",
        "\r\n",
        "            # Update start mask\r\n",
        "            G_mask_start_copy = G['mask_start'].detach().clone()\r\n",
        "            G_mask_start_copy[G['num_nodes']] = False\r\n",
        "            G['mask_start'] = G_mask_start_copy\r\n",
        "            \r\n",
        "            G['num_nodes'] += 1\r\n",
        "\r\n",
        "        return p_start, a_start_idx, p_end, a_end_idx, G"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phoYQYmlSw75"
      },
      "source": [
        "rollout = 10\r\n",
        "max_gen_step = 10"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMDgOdT4pmj9"
      },
      "source": [
        "args.lr = 0.01\r\n",
        "args.b1 = 0.9\r\n",
        "args.b2 = 0.99\r\n",
        "args.hyp1 = 1\r\n",
        "args.hyp2 = 2\r\n",
        "\r\n",
        "candidate_set = ['C.4', 'N.5', 'O.2', 'F.1', 'I.7', 'Cl.7', 'Br.5']\r\n",
        "g = Generator(candidate_set, c=0, start=0)\r\n",
        "optimizer = optim.Adam(g.parameters(), lr=args.lr, betas=(args.b1, args.b2))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R66u9R5WFzGY"
      },
      "source": [
        "def train_generator(c=0, \r\n",
        "                    initial_node=None,\r\n",
        "                    max_nodes=5):\r\n",
        "  g.c = c\r\n",
        "\r\n",
        "  for i in range(max_gen_step):\r\n",
        "\r\n",
        "    optimizer.zero_grad()\r\n",
        "    G = copy.deepcopy(g.G)\r\n",
        "    p_start, a_start, p_end, a_end, G = g.forward(G)\r\n",
        "\r\n",
        "    Rt = g.calculate_reward(G)\r\n",
        "    loss = g.calculate_loss(Rt, p_start, a_start, p_end, a_end, G)\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    if G['num_nodes'] > max_nodes:\r\n",
        "      g.reset_graph()\r\n",
        "    elif Rt > 0:\r\n",
        "      g.G = G\r\n",
        "\r\n",
        "def generate_graph(c=0, max_nodes=5):\r\n",
        "  g.c = c\r\n",
        "  g.reset_graph()\r\n",
        "\r\n",
        "  for i in range(max_gen_step):\r\n",
        "    G = copy.deepcopy(g.G)\r\n",
        "    p_start, a_start, p_end, a_end, G = g.forward(G)\r\n",
        "    Rt = g.calculate_reward(G)\r\n",
        "\r\n",
        "    if G['num_nodes'] > max_nodes:\r\n",
        "      return g.G\r\n",
        "    elif Rt > 0:\r\n",
        "      g.G = G\r\n",
        "    \r\n",
        "  return g.G"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rURRIXGoK0Hb"
      },
      "source": [
        "Visualizing graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfVsy8X-Ab1a"
      },
      "source": [
        "import networkx as nx\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "def display_graph(G):\r\n",
        "  G_nx = nx.from_numpy_matrix(np.asmatrix(G['adj'][:G['num_nodes'], :G['num_nodes']].numpy()))\r\n",
        "  # nx.draw_networkx(G_nx)\r\n",
        "\r\n",
        "  layout=nx.spring_layout(G_nx)\r\n",
        "  nx.draw(G_nx, layout)\r\n",
        "\r\n",
        "  coloring=torch.argmax(G['feat'],1)\r\n",
        "  colors=['b','g','r','c','m','y','k']\r\n",
        "\r\n",
        "  for i in range(7):\r\n",
        "    nx.draw_networkx_nodes(G_nx,pos=layout,nodelist=[x for x in G_nx.nodes() if coloring[x]==i],node_color=colors[i])\r\n",
        "    nx.draw_networkx_labels(G_nx,pos=layout,labels={x:candidate_set[i].split('.')[0] for x in G_nx.nodes() if coloring[x]==i})\r\n",
        "  nx.draw_networkx_edges(G_nx,pos=layout,width=list(nx.get_edge_attributes(G_nx,'weight').values()))\r\n",
        "  nx.draw_networkx_edge_labels(G_nx,pos=layout,edge_labels=nx.get_edge_attributes(G_nx, \"weight\"))\r\n",
        "\r\n",
        "  plt.show()"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goIcA-sgKqzi"
      },
      "source": [
        "Train graph with different max_nodes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6vnCRE6kOjpQ",
        "outputId": "6671153b-eb57-4ba9-a980-28b93e4a73e1"
      },
      "source": [
        "for i in range(1, 10):\r\n",
        "  g.reset_graph()\r\n",
        "  train_generator(c=1, initial_node=0, max_nodes=i)\r\n",
        "  to_display = generate_graph(c=1,max_nodes=i)\r\n",
        "  display_graph(to_display)\r\n",
        "  print(g.model(to_display['feat'],to_display['adj'],None))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([0.2437, 0.7563])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([0.2180, 0.7820])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([0.4255, 0.5745])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([0.1308, 0.8692])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([0.1110, 0.8890])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([0.1127, 0.8873])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([0.0923, 0.9077])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([0.1742, 0.8258])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAEuCAYAAADx63eqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3daXxU5d3/8c/JvhASDEtYAwaMEgiIgCiEVaui1iJoQYho60upS2+9+1cUEKFsFttKrWWpWKQaQXqzSrUtW1gFIQgICSGEsBOQELJvM3P+D9JEYkKIyWQmmfm+H8mcM9f5Tat+va5zLYZpmiYiIiJuwsPZBYiIiDiSgk9ERNyKgk9ERNyKgk9ERNyKgk9ERNyKgk9ERNyKgk9ERNyKgk9ERNyKgk9ERNyKgk9ERNyKl7MLEBFxlKTMXCYfTCGxIJ8800ag4UFX/wDm9OhCZLMmzi5PHMTQXp0i4uriUs4zOSWV074WAExPo/yaYS39V2B4sRczO0cwtksbp9QojqPgExGX9vSOQywtysA0AA/j+jfaTAwTxvuGsmRAtMPqE8dT8ImIyyoPPc9qAu8HDKup8HNxCj4RcUlxKeeJPZ1cOfRGj4bMTPC4Zm7fxx9D8+blfzSsJnHhkYzprGFPV6TJLSLikianpGL6Xefi7Nlwxx3X/a5pwKRjqQo+F6XlDCLicpIyc0snslT3Tq86HganfC0kZ+batzBpEBR8IuJyJh9MsUs7k+zUjjQsGuoUEZeTWJCP6V9Nb2/KFPD0LP3rnj1h5sxKt5ieBokF+fVUoTiTgk9EXE6eaav+hpkzq33HV+N2pFHSUKeIuITc3FwWL17Mww8/TMaZs3ZpM9DQvyJdkXp8ItIopaamsnTpUjZs2EBiYiLZ2dn4+fnRuXNn2pdYSLGaP2r93g8ZVpOu/gF2rFgaCgWfiDR4NpuNLVu2sHz5cnbs2MGJEycoLi6mWbNmdO/enddff53Y2FjatWsHlM7qjNq/t87Pnd2jS53bkIZHC9hFpMHJzc1l+fLlrF27loSEBNLT0zEMg7Zt29KnTx8effRRRo4ciZ/f9RbqQccvtnPKr5ZLGmwmHQu9SBseU4dfIQ2Venwi4nTVDVuOGDGCJ554grvuugsPj5q/c5vVJaJ055Za1GOYMPuWiFp8UxoD9fhExKF+OGyZlpZGUVFR+bDl/fffX2HYsi60V6dURcEnIvXqRsOWI0aMYNSoUdUOW9aFTmeQH1LwiYhdVTdsOXDgwFoNW9bVsuPnmXQslVPVncdX5MXsWyK0P6cbUPCJuLH9+/eTkZHBvffeW6vvO3LY0h6SM3OZVMUJ7LN1ArtbUfCJuDjTNDGMikN8hYWFTJgwgQMHDhAREcHNN9/MO++8c8O2fjhsefHiRQCHDVuK2INmdYq4qLNnz3LixAkGDhxY6Vpqairnzp3jwIEDAERGRjJmzBh69epV4b78/Hzmzp3Lf/7zHxITE8nKyqrzbEsRZ1PwibigSZMm8fe//52srCxOnDhBixYtKlzftWsXAwYM4PLlyzRv3pyf/OQnbNiwgejoaLy8vv/XgsVi4b333qN79+5MnDixQQ1bitSW/jNNxAWNHj2ahIQE7r//fnbu3AmUvo+z2b7fdDkrKwvP/55QEBMTQ3JyMvn5FU8jCAoK4sqVK2zdupU33nhDoScuQcEn4oK6d+9Oq1at6NKlC9u3bwcqvuvr0aMHp0+fJjMzE4BevXpx+PBh/P39K7Tzw3eDIq5AwSfigsoCq1+/fnzzzTfln5V93r17dwICAtizZw8AN998M5mZmRQWFjqnYBEH0js+ERdgsVgqvJsr0717dy5dukReXh6BgYHln/v7+xMbG8sf/vAHAL7++mueeOIJzcYUt6Aen0gjlJaWxrRp07j77rsJCQnhxRdfJC8vr9J9nTp1ol27dqSnpwOlszSPHDlCeno69957LxMmTGDNmjXk5+cTGxuLt7e3o3+KiMNpHZ9IA1eTReJPP/00YWFhlb574sQJRo4cyfnz5xkxYgT33nsvubm59O/fn86dOzvh14g4n4JPpIHJzc3ls88+Y82aNXVaJJ6Zmcmjjz5KWFgYw4YNY9iwYXTq1MkRP0GkQVPwiThZWloaS5curXKRuLP2thRxZQo+cQtJaWeY/Lv3STzyLXk5OQQGBdE1qjtzJr5EZCfHrU1rbHtbirgiBZ+4tLj1m5k8bQanD+wEw8C0FJdfM7x8wDQJ79mfmdPeZOxDQ+3+/LJhy3Xr1rFv377ySSba21LEeRR84rKefm0mS+fNxCwphmrP4TYwvH0Y//IUlsydUqdnathSpOFT8IlL+j70imr8HcPb90eFn4YtRRonBZ+4nLj1m4l9dPiPCr0yhrcvcau/ZMyDQypd07CliGtQ8InL6dh7CKcStlL98Ob1GHTsPZi0vZs1bCniohR84lKS0s4Q1SUC01pS+0Y8vfENbEpRdoaGLUVckPbqFJcy+XfvQx1PFDAMgx6DHmDrig80bCnigjRGIy4l8ci3FZYs1IZpKSb7aqZCT8RFKfjEpeTl5NipnSy7tCMiDY+CT1xKYFCQndoJtks7ItLwKPjEZezdu5fcvHzw9KlTO4aXD12jutmpKhFpaBR80qhlZ2fzv//7v7Ro0YI777wT/6KrGLVaxnAN02T2ay/ap0ARaXAUfNIorVixgp49exISEsJHH33EqFGjuHTpEilHDtChZ3+gtjM7DcJvH+DQjatFxLEUfNJopKam8thjjxEQEMATTzxBcHAw8fHxXLlyhQULFtC8eXMAZk17E8O7dsOdhrcPs6e9ac+yRaSBUfBJg1ZcXMycOXPo0KEDnTt35uuvv2bq1Knk5+ezdetWBg4cWOk7Yx8ayviXp2B4+/6oZ5Xt1VnVdmUi4jq0gF0apPj4eKZOncquXbvw9fXlwQcfZMuWLURERNTo+2UbTTv6dAYRafjU45MG4/Lly0yYMIFmzZoxdOhQcnJy+PTTT8nLy2PFihU1Dr0yS+ZOIW71l3TsPRjD07v0/L1rGF4+GJ7edOw9mLjVXyr0RNyE9uoUp7LZbCxZsoTf//73JCcn07x5c2JjY3nrrbdo2rSp3Z6TnHaWSXPfJ/HIYfJysggMCqZrVDdmv/aiJrKIuBkFnzjF4cOHeeONN9iwYQM2m40hQ4Ywa9Ysevfu7ezSRMTFaahTHCY/P5/JkyfTunVrunfvztGjR/n9739PYWEh//73vxV6IuIQmtwi9W79+vX89re/JSEhgcDAQB599FFmz55NmzZtnF2aiLgh9fikXpw9e5bx48cTFBTEI488goeHB+vXryc7O5uPPvpIoSciTqPgkxo5deoUc+bM4dChQ1gsFgB++HrYNE3+9Kc/ERERQfv27dmwYQOvvPIKeXl57N69mwceeMAZpYuIVKDJLXJD//73v5k0aRLdu3fHYrEQERHB9OnTMU0T45pDX7Ozsxk9ejQ+Pj7MmjWLqKgoJ1YtIlI1BZ9cV1mwvffee6SnpzN79mwOHjzIk08+yfr162nfvn2F+202G4ZhVAhDEZGGRkOdAkBmZib79+8HwGq1AmAYBlarlczMTCIjIyksLKRHjx706NGDzz//nJKSkgpteHh4KPREpMFT8Lk5m83Gq6++SqdOnRg1ahQAnp6eQGmPz9PTE6vVypkzZyguLgbg4YcfZsuWLQo5EWmUFHxuzsPDg169erFz506ioqJYvXo1UNrrKxsFv//++/nmm2+4cOECAD/96U9JSEggMzPTaXWLiNSWgk8YNWoUUVFR3HPPPXzyySdA6TCnh0fp3x533303oaGhrFu3jqKiInx9fbn99tvLg1BEpDFR8Ane3t4A/OxnPyMlJYULFy7g4eGB1WrFZrMB8OKLL3Lq1CmefPJJ+vbtS1BQENHR0c4sW0SkVjSr002ZponNZit/n1dm3LhxdOvWjddff738s++++44WLVqQk5PD8uXLadu2LcOHD3d0ySIidqHgczOHDx/m9ddf5+zZs+zatYuAgIAK13ft2sXUqVNZtWoVSUlJHD16lJKSEsaNG4efn5+TqhYRsR8NdbqB/Px8Jk2aROvWrYmOjubYsWM8++yz+Pv7V7r36NGjbN68mfbt25OUlMSDDz7IM888o9ATEZehTapd2Lp165gxYwb79+8nMDCQkSNHMmvWrOvuk5mQkMDKlSv55JNPeOKJJxxcrYiIY2io08WcPXuWSZMmsXr1avLz8+nTpw9vvfWW9skUEfkvDXW6AIvFwrx588o3h960aRO/+c1vtDm0iEgVNNTZiO3Zs4fJkyezdetWPD09uf/++1m/fj233Xabs0sTEWmw1ONrZLKzs3nllVdo3rw5d911FxcuXGDx4sXk5+ezZs0ahZ6IyA2ox2dn6Wm5bPtdCoVH8jFybJhBHvhFBTBoYhdadWpS63aXLVvGnDlzOHz4MCEhIYwZM4YZM2Zw00032bF6ERHXp8ktdpKw/jyJ01IJO2DBNMDH8v0GzsVeJoYJ6T296Dotgjseqtnp4ykpKbzxxht88cUXFBcXM2DAAGbOnMmAAQPq62eIiLg8BZ8drH7tEAHzMvAuAQ+uf2KBDZMSb8h/OZQRc6ve7qu4uJh33nmHRYsWcebMGcLDw3nhhRd45ZVX8PJSB11EpK4UfHVUFnq+JTU/oqfI26wUfps3b2bq1Kns3r0bX19ffvrTnzJ79mw6depUH2WLiLgtTW6pg4T1568beqMZTQIJVX7Pt8QgYF4G8cuO8uyzzxISEsI999xDQUEBn332GXl5eSxbtkyhJyJSDzR2VgeJ01JpW3Lj+6riXQK7/99B1lrW8uyzzzJ16lSaNKn95BcREakZBV8tpaflEnbAUu07vep4YNDrYksOpaTWabaniIj8OBrqrKVtv0vBrF3mfc+ArXNT7FKPiIjUjIKvlgqP5FdYslAbPhaDoiP5dqpIRERqQsFXS0aOzT4N2asdERGpEQVfLZlBdvqfzl7tiIhIjejfurXkFxVAsVfdlkAWe5n4RgXc+EYREbEbBV8tDZzYBaOOS/8NEwa91sU+BYmISI0o+GqpaSsPDre7io2q0285y7mDO677fRsm6bd7aSmDiIiDKfhqYdu2bbRq1Yp/8DEltVwJWeINUdMi7FuYiIjckILvR/qf//kfBg8ezNChQ9l2fAX5r4RS5P3jxjzL9urs9WDNTmkQERH70SbVNXTp0iViYmJIS0tj8eLFPPnkk+XX7Hk6g4iI1C/1+GpgxYoVtG/fHovFwsmTJyuEHsCIudG0WB3Jud5elHialWZ7FnuZFHuanOvtRYvVkQo9EREnUo+vGjabjccff5xVq1bx3HPPsWDBght+52JaLlvnppTuyJJjgyAPfKMCGPRa3U5gFxER+1DwXUdycjKDBg0iJyeHdevWMWzYMGeXJCIidqChzir88Y9/JCoqivbt23Px4kWFnoiIC1HwXaOwsJCYmBheffVVpk+fzt69e3VGnoiIi9F5fP+1c+dOHnjgAXx8fPjmm2+IjtYEFBERV6QeH7Bnzx5iYmKIiYkhPT1doSci4sLcYnJLWloarVq1IiAgANM0MYyKa+3y8vLYs2cPQ4cOdVKFIiLiKC4dfEVFRYwcOZLs7GwCAwN5/vnnefjhh51dloiIOJFLD3UuWrSI0NBQtm3bxjPPPMPUqVPZuXMnNpsOfxURcVcuObmlbDgzJCSEwMBAAEaOHMnp06eZP38+4eHhtGvXzslVioiIM7hkj6/sHV5wcDD+/v6cOnUKgFdeeQWLxcLixYuB0oAUERH34nLBd+0w5uDBgzl16hT/+c9/yMrKAmDGjBl89tlnpKenV5rkIiIirs8lgu+ll17iD3/4A/B9b89msxEcHMxLL73EP//5TzZs2EBRURE333wzt99+O0FBQc4sWUREnKRRv+MrKSkhNjaWkydPEh8fT69evRgyZAhWqxVPT08ABg0axMWLF9m6dSt/+9vfOHv2LDExMeXv/kRExL00+uUM27ZtIzo6mi+++IJ58+axefNmmjRpgtVqBSgPwKKiIjZu3EhQUBADBw50ZskiIuJEjT74ypimyfPPP09ubi4ff/xx+ec5OTkcOXKEfv36ObE6ERFpKFziHR+UvtubPn06J0+e5MMPPwQgNTWV5cuXU1BQ4OTqRESkoXCZHl+Zb7/9lnHjxtG6dWuioqJ47bXXaNWqlbPLEhGRBqJR9/hKSkoqfebv78+ZM2do0qQJs2bNUuiJiEgFjTL4iouLGTJkCH/6058oLi4u/9w0Td5++21mzJjB//3f/+Hn5+fEKkVEpCFqdEOde/bs4b777sPDw4ONGzfSq1evCtctFgteXo16lYaIiNSjRtXje+ONN7jrrrvo168f6enplUIPUOiJiEi1GkVKXLlyhUGDBnH06FH++te/8swzzzi7JBERaaQafPCtXbuWn//857Rs2ZLU1FQ6dOjg7JJERKQRa7BDnTabjXHjxjFixAjGjBnDyZMnFXoiIlJn9d7jS0orYvLvckg84kFejkFgkEnXKBtzJgYR2cm3yu+kpaURExNDRkYG69evZ/jw4fVdpoiIuIl6m9UZtz6HydMsnD7QFAwwLZ7fP9TLAqZBeM9sZk7zYuxD35+UsGDBAl566SW6detGfHw8ISEh9VGeiIi4qXoJvqdfu8zSeSGYJR5UP5pqw/C2Mf7lqyya2ZThw4ezZcsWJk2axIwZM+xdloiIiP2DrzT0mmGWeN745rIivC0EtvsQr8zX2bBhA71797ZnSSIiIuXsGnxx63OIfdQfs+SHrw4/Bf4IHAWCgJ7AZGDA94V4WVj6fznEPtLMXuWIiIhUYtfg69g7k1MJwVQc3vwj8DawELgP8AH+BWwD3rnmPhsde18lbe9N9ipHRESkErsFX1JaEVFdvDCt1w5xZgFtgSXAYzcuxtNKUorlurM9RURE6spu6/gm/y4HjB9++hVQCIyoWSOGyaS5OfYqSUREpBK7BV/iEY8KSxZKZQDNqelyQdPiReKRBrumXkREXIDdUiYvp1J3DwgFLgOWOrYjIiJiH3YLvsCgql4V3gX4Amvq2I6IiIh92C34ukbZMLysP/g0GPgt8AKl4ZcPlABfAq9VasPwstA1ymavkkRERCqp51mdZeKAd4EkStfx3UHpOr67KxajWZ0iIlLPHLCOr6a0jk9EROqfXadQzprmheFdu6FKw9vG7Gne9ixHRESkErsG39iHghj/8lUM75rP4oTSvTrHv3yVMQ8G3fhmERGROmgwpzMsmdvc3mWIiIhUUi+rxZfMbU7c6gI69r6K4WktPX/vGoaXBcPTSsfeV4lbXaDQExERh6m3g2jLJKcVMWluDtu3ZZKTBR1vDqVrlI3Zr13/BHYREZH6Uu/BV2bq1KksWrSIixcvOuJxIiIiVXJY8KWlpXHx4kX69evniMeJiIhUyWHBJyIi0hDoKAQREXErCj4REXErTg++kpIScnNznV2GiIi4CYcF38iRI6v8/MiRIwwfPhyr9YcnO4iIiNhfzY5Gt4M9e/awa9cuvL29yc3NpaioiPz8fAoKCti7dy+FhYUEBgY6qhwREXFTDpvV2bJlS1q0aEHTpk3x8vLC29sbX19f/P39uemmm3j//ffx8/NzRCkiIuLGHNbja9GiBTt37iQkJMRRjxQREanEYcH35ptvlv+1zfb90UVlHU5Pz6oOsBUREbEvhwVfUVERxcXFABiGgWEYjnq0iIhIOYfN6vTz8yvv3Sn0RETEWRy+ZVlubi45OTkUFhZitVoJDQ2lWbNmjixBRETcmMOGOgF27tzJypUrSUtLw2q1EhQURPv27XnggQe4++678fb2dmQ5IiLihhzW4/vwww+Ji4tj1KhRDBw4EH9/f/Lz89m0aRPr1q1j2rRpDBw40BGliIiIG3NYjy8+Pp4nn3ySp556qsLn3bt3JyEhgSNHjij4RESk3jks+Dp06EBCQgIDBw7E19eXgoICCgoKSElJwWq10qVLF0eVIiIibsxhQ52FhYW88847fPzxx7Rs2ZKbbrqJnJwcrFYrL7/8Mo8++qgjyhARETfnlINoMzIyyMnJITQ0lKCgIEc/XkRE3JjDg880zQrr+Mp2cfHwcPoJSSIi4gac0uMTERFxFnWzRETErTg0+PLy8sjLy3PkI0VERCpwaPBNmzaNxx9/3JGPFBERqcChwZeRkcGxY8cc+UgREZEKHDK5JSkzl8kHU9h+9gy5NgvhLVrR1T+AOT26ENmsSX0/XkREpFy9Bl9cynkmp6Ry2tcCgOn5/TIGw1r62PBiL2Z2jmBslzb1VYaIiEi5egu+p3ccYmlRBqYBeFRz/p7NxDBhvG8oSwZE10cpIiIi5eol+MpDz7PmB84aVlPhJyIi9c7uwReXcp7Y08mVQ2/0aMjMhGt3aPn4Y2je/PtirCZx4ZGM6axhTxERqR92P51hckoqpt91Ls6eDXfccd3vmgZMOpaq4BMRkXpj1+UMSZm5pRNZqnunV201Bqd8LSRn5tqzLBERkXJ2Db7JB1Ps0s4kO7UjIiLyQ3Yd6kwsyMf0r6a3N2UKeHqW/nXPnjBzZqVbTE+DxIJ8e5YlIiJSzq7Bl2faqr9h5sxq3/HVuB0REZFasutQZ6Bhn+bs1Y6IiMgP2TVhuvoHlO/IUluG1aSrf4CdKhIREanIrsE3q0cXu7QzMzrCLu2IiIj8kF2D77ZmTehQ5AW2Knp9y5ff+P2ezcTn5Hf0bt+at99+G5tN7/pERMS+7P4ybVaXCIxajnYaJnwYcxfPPvssU6dOJTQ0lMWLF9u3QBERcWt2D76xXdow3jf0R7/rK9urc+wt7Xn33XfJzs7mkUceYcKECbRu3ZqVK1fau1QREXFD9TJ9csmA6O/Dr6phz2vZzCo3qPbz8+Ojjz7i8uXL3HnnnTz22GN06tSJ+Pj4+ihZRETcRL2tG1gyIJq48Eg6FnphWM1KPcCyzzoWehEXHnndUxlCQkJYs2YNZ8+epVOnTgwdOpRu3bqxf//++ipdRERcmENOYE/OzGXSwRQSC/LJM20EGh509Q9gdi1OYE9OTmbs2LHs37+fPn368OmnnxIRoVmgIiJSMw4Jvvqwd+9ennzySZKTkxk6dCiffPIJYWFhzi5LREQauEa7RUqfPn1ISkri3//+N8ePH6dt27aMHDmS7OxsZ5cmIiINWKMNvjL33nsvJ0+eZNmyZezYsYObbrqJX/ziFxQWFjq7NBERaYAaffCVefzxx7l48SJ//vOfWbVqFcHBwfzmN7/RIngREanAZYKvzK9+9SuuXLnCm2++yYIFCwgKCmLOnDnXDUDTNJk+fTpffvmlgysVERFncLngA/Dw8GDKlClkZ2fz3HPPMW3aNH7+859TUlJS6d4rV64QFBTEyJEjmVnF+YAiIuJaGu2szh+jsLCQrKwsWrVqdd3rQ4cOZcaMGQwbNgybzYaHh0v+N4GIiNuz60G0DZWfnx9+fn7XvT5v3jxatmzJsGHDAMpDzzRNDKOaE+VFRKTRcftuzfnz51mxYgVvvPEGAFartfyaYRgUFxfz5ZdfcunSJWeVKCIiduT2wTd//nwiIyO58847MU0TT09PykZ/t23bxksvvcRf/vIXevbsyXvvvefkakVEpK7cMviKior461//yvHjx9m4cSNvvfUWADabDZvNhmEYpKamMn/+fHr06MH69evZsmULx44dq3KCjIiINB5uG3zx8fF0796djIwMbr31VgA8PT3L71m4cCGdO3dm5MiRAGRnZ7N582a8vb2dUrOIiNiHWwZf06ZN+fTTT9mzZw9t27bl7bffJikpCSid2JKamkpaWhoPP/wwLVu2BOCDDz7g8ccfByq+BxQRkcbFLYOvTHR0NPHx8Tz11FN88803/O1vf8NqtZKZmUloaCihoaEYhkFCQgLnzp1jxIgRQMWeoYiINC5usZzhRsLCwnjiiSf47rvv8PT0pGnTpqSkpNC5c2cA3nrrLWJiYoiMjHRypSIiUlcKvmu0aNECKB0KbdKkCTExMfTp04fMzEwmTpxYYU1fSUmJ3veJiDRCbj3UeT1hYWGsW7eOp59+muHDh7Nq1SoMw6jwbu/o0aO0atWKFStWOLFSERH5sdxiy7L6kJeXR2xsLGvXrqV9+/Z88MEH3Hvvvc4uS0REbkA9vloKDAxk1apVnDt3js6dO3Pfffdx2223sW/fPmeXJiIi1VDw1VFYWBgbN24kOTmZpk2b0rdvX3r37k1ycrKzSxMRkSoo+OykS5cu7Nmzh3379lFQUMBtt93G0KFDOX/+vLNLExGRayj47KxXr14cOXKEjRs3kpaWRrt27fjZz37G1atXnV2aiIig4Ks3Q4cOJS0tjRUrVrBnzx6aN2/O+PHjKSwsdHZpIiJuTbM6HeSvf/0rEydOJC8vjxdeeIF33nkHL6+aL6NMzzzDtoPvU1jwLYaZg2kE4effnUE9XqJVs3b1WLmIiGtR8DmQzWZj7ty5zJgxA9M0ef3115kyZUq1p70npGwmMWUGYb47MTHw8Swuv1Zs9cHAJL24P107v8kdXYY64meIiDRqCj4nsNlsTJw4kffeew8/Pz/mzJnD888/X+m+1TtmElA0E2+jGA+P6//fZLMZlJg+5PtOYcSAKfVZuohIo6d3fE7g4eHBO++8Q1ZWFo899hi//vWvadmyJZ999ln5PWWh5+tZVG3offQRzJlj4utZREDRTFbvmOmAXyAi0nipx9cAZGdn8/TTT7NmzRratm3LjPf+H2FBr+HrWVR+z8aN8I9/wOnTEBAAnTvDuHGQkADnzsHkyaX3FVl9aRH+Jb06D3HSrxERadjU42sAmjZtysqVKzl37hyRkZGkZ8zH2/j+Xd6KFfCXv8DYsbBqFXz2GTzyCOzcWbktb6OYI8dmOLB6EZHGRT2+BiY98wzf7o/A27MEgNxceOwxmDgRBg+ufP9HH1Xs8QGUWL2J7nVCsz1FRKqgHl8Ds+3g+5h8f/xRYiIUF0NMTM3bMDHYevD9eqhORKTxU/A1MIUF31ZYspCVBcHB8GMOfffxLKao4HA9VCci0vgp+BoYw8yp8Ofg4NLwu+YowJoxs+xXlCoNGBcAABDdSURBVIiIC1HwNTCmEVThz127go8P7NjxIxsygu1XlIiIC1HwNTB+/t0ptvqU/7lJE3j6afjTn0rDr7AQLBbYswcWLqy6jSKLD7t2f8cLL7zAkSNHHFS5iEjjoOBrYAb2eBGDihNtH38cfvUr+PhjGDGi9M+rV8OAAVW3YRgmWac6sGrVKrp164a/vz99+vRhzpw5XLlyxQG/QkSk4dJyhgbo4y+G0NZva7U7tlyPzWZwrnAwscM3A1BYWMjSpUtZvnw5+/fvJzs7m2bNmtG3b1/GjRvH6NGjf9Rm2SIijZ2CrwFKSNnM5dPDK+zcUlM32rnl7NmzLFq0iHXr1nH06FFKSkpo164dQ4YM4dlnn6V///51LV9EpEFT8DVQ1+7VWVNFVt8fvVH1nj17WLRoEZs3b+b06dN4eXlxyy238OCDD/L8888THh5em/JFRBosBV8D5ujTGSwWC6tWreLvf/87u3fvJiMjgyZNmnD77bfz+OOP84tf/IKAgIBaty8i0hAo+Bq4/ce3cOTYDMJ8d1R5Hh+YXCwaQNQtb9p9Y+qrV6/ywQcfsHLlSg4dOkRBQQEtW7akf//+PPXUUzz00EPVniUoItIQKfgaiYuZZ9l68P3SHVnMLDCC8fXvxqAeLzpsT87k5GQWLlzIl19+yfHjxzFNk06dOvGTn/yE559/nm7dujmkDhGRulDwSa3YbDY2bdrEhx9+yLZt20hPT8fX15eoqCh+9rOfMWHCBJo3b+7sMkVEKlHwiV0UFhbyySefsGzZMvbt20d2djYhISH07duXsWPHMnr0aHx8fG7ckIhIPVPwSb04f/48CxcuZN26dSQlJVFSUkKbNm0YPHgwzz77LAMHDqxVu7t37+bYsWPcd999tGrVys5Vi4g7UPCJQ+zdu5dFixaxadMmTp8+jYeHR/myiRdeeKHGyyb+/Oc/s2LFCpKTk0lOTqZZs2YVrpumiWEY1/m2iIiCT5zAZrOxatUqli5dyldffUVGRgaBgYH07NmTxx57jF/+8pc0adKkyu9aLBb27dvHq6++yvbt26sMukuXLtGyZUtH/BQRaYQ0F10czsPDg1GjRvH5559z+fJlMjMzmT59OlarlUmTJhEUFMTVq1er/K6Xlxdr166ld+/eQGmIXmvnzp2MHz+ejh078vzzz1e6LiKi4BOnCwkJ4Te/+Q1fffUVeXl5nDx5En9//yrvtVqt7N27l/vuuw8AwzDKw23Lli0sWbKEMWPGkJKSgtVqJT4+3lE/Q0QaCQWfNDjh4eH4+vpW+tw0TdLS0rh48WL55BgPD4/yoc6VK1fSq1cvhg8fjre3N5cvXyYpKQmo3DMUEfel4JNGwzAMUlNTCQ8PJyAgAIvFUv6Or7CwkBMnTtCzZ8/y9YOZmZl0794dQDvMiEg5nUcjjcJXX33FvHnzOHbsWHlv79rjlBITEwkNDS2f1JKWloa/v78muYhIJQo+aRSio6N56KGH+Ne//sWyZcto3bo1d955Jy1btiQqKgo/Pz+8vLwoKCgA4F//+hehoaEVlknYbDb1/EREQ53SOAQGBhIbG0tcXByXLl3iueeeIygoiIMHD5Kfn0/Xrl0pKCjg8OHD5ObmsmzZMu67774Kk2Ty8vLo168f/fv3Z968eWRnZzvxF4mIs2gdn7iMzz//nNmzZ5Obm8vLL7/MU089haenZ/l10zR59913WblyJQcPHiQvL48WLVpw9913Exsby4gRI9QjFHEDCj5xOYWFhfj5+d3wvtTUVObPn88XX3zB8ePHsdlshIeHc8899zBhwgR69erlgGpFxNEUfCL/tXnzZhYvXszWrVu5cOECPj4+dO3alUceeYTnnnuOsLAwZ5coInag4BOpQnFxMXFxcXz66afs3buXrKwsgoOD6d27N2PGjCE2NlanTYg0Ugo+kRpIT09n0aJFrF27lsTERIqLi2ndujWDBg3il7/8JUOGDNH7QZFGQsEnUgsHDhxg4cKFbNiwgZMnT+Lh4UHnzp154IEHeOGFF4iIiHB2iSJyHQo+kTqy2WysXbuWpUuXsmvXLr777jsCAgLo0aMHo0aN4plnnqFp06b1WkNSWhGTf5dD4hEP8nIMAoNMukbZmDMxiMhOlbd/E3FnCj4RO8vOzmbJkiX84x//4MCBA+Tl5REaGspdd93F+PHjefTRR+02LBq3PofJ0yycPtAUDDAt3y/fMLwsYBqE98xm5jQvxj4UZJdnijR2Cj6RepaWlsb8+fP55z//SUpKCjabjQ4dOnDPPffw3HPPlR+x9GM9/dplls4LwSzxoPq9KGwY3jbGv3yVJXOb1+pZIq5EwSfiYPHx8SxevJj4+HjOnz+Pt7c3t912Gz/96U+ZMGECbdq0uWEbpaHXDLPE84b3ljG8LQo/ERR8Ik5VXFzMsmXLiIuLY+/evVy9epWmTZuWL5sYN25cpcX4cetziH3UH7Okqq12PwX+CBwFgoCewGRgAFAafnGrCxjzoIY9xX0p+EQakEuXLrFw4cLyZRNFRUWEhYUxcOBAfvnLXzJs2DBu7pvFqYRgKg9v/hF4G1gI3Af4AP8CtgHv/PceGx17XyVt702O+kkiDY6CT6QBO3ToEAsWLOA///lP6bIJ/85YChPB+sMhziygLbAEeKzaNg1PK0kpFs32FLel4BNpJGw2GzEjk9i1PhIsPxzm/BfwEFDIjU4bM7wsjHjmKisX6F2fuCdtNSHSSHh4eJBxuXUVoQeQATSnJkdsmhYvEo/oH31xX/q7X6QRycsxrnMlFLgMWGrUTmaGheLiYnuVJdKo6AR2kUYkMOh6bybuAnyBNcCoG7ZzNfs0vr6t8PHx4aabbqJ9+/bceuut3HHHHQwaNIjo6GjtPSouS8En0oh0jbJxbLe1wg4tpYKB3wIvUPqP9U8Ab2AjsAWYW36n4WXhwYc6smjGd8THx7Nnzx4OHTrEV199xZo1a8jNzcU0Tfz9/WnevDkdO3aka9eu9OnTh6FDh9KpUyfH/FiReqLJLSKNSFJaEVFdvDArzeosEwe8CyRRuo7vDkrX8d1dfkdNZnWmpaURHx/P119/TWJiIidPnuS7776joKAAwzAIDAykVatW3HzzzXTv3p0777yTwYMH07JlS7v9VpH6ouATaWQ69s68zjq+mqjbOj6bzcbhw4fZunUr+/bt4+jRo5w5c4YrV65QVFSEp6cnTZs2JSwsjC5dutCjRw/uuusuYmJiaNKkSa2eKWJvCj6RRqb6nVuqV587txQXF/P111+zfft29u/fz7Fjxzh//jxXr17FYrHg7e1NSEgIbdu2JTIykl69ehETE0OfPn3w8tJbF3EcBZ9II/T9BtU1Dwxn7tWZnZ3Njh072LlzJwcPHiQ1NZX09HSys7Ox2Wz4+voSGhpKhw4duPXWW+nTpw+DBg3itttu0yQbsTsFn0gj5SqnM6Snp7Nlyxa+/vprvv32W9LS0rh06RJ5eXmYpklAQAAtWrSgU6dOdO3atfx9YocOHeqtptWrVzN//nwiIyOZPn06oaGhFa6bpolhXG9piTR0Cj6RRmzZP3OYNK2EU98Eg2FiXrO4vfw8vtuzmD3Nu1FuTJ2SksKWLVvYt28fiYmJnDp1isuXL1NYWIiHhwdNmjShVatWREREEB0dTb9+/RgyZAghISF1eu6mTZtITU1l0qRJfPvtt7Ru3br8Wlnoff311yQlJdGpUyf69++Pp2fNT8oQ51LwibiA5LQiJs2tfAL77Ndc8wR2m83G/v372bZtGwkJCSQnJ3P27FkyMzMpLi7G09OT4OBg2rRpQ5cuXejZsycDBgzg7rvvrnTaRVVM0+TChQs89NBD7N+/v9L1Y8eO8etf/5pWrVqRlJTEtGnTGD58eH38VKkHCj4RcSmFhYXs2rWLHTt2cODAAY4fP865c+fIysrCarXi4+NDs2bNaNeuHZGRkbz77rtVLsPYtGkTb731Fjt27KgwtJmXl8e0adMIDg5mypQpJCUlMW7cOBISEhz9U6WWNJVKRFyKn58fQ4cOZejQoZWuXb16la1bt7Jr1y4OHTrE3r178fWtukd84sQJ2rZtC5T2MD08PDAMg7S0NE6dOsVvf/vb8msa5mxcFHwi4jZCQkJ45JFHeOSRR254b0pKCh07dgRKhz7Len0nTpwgMDCwfMLLmTNn6Ny5M1lZWQQHB9dn+WInmicsIlKFjIwMBg8eDICXl1f5soqMjAzCwsKw2WwAJCcn07JlS3x8fCp8X2+RGi71+ERErvHBBx+wYMECDhw4QEZGBuHh4TRv3pzg4GB8fX259dZb2bhxY/n927ZtY9iwYfj7+1do5+jRo0RHRxMSEkKbNm245ZZbyhft9+3bt1JQiuNocouIyDWKiopISkri+PHj7N69m379+lFSUsLly5d56qmnCAoKIjY2ljZt2tCxY0c+//xz3n33XSIjIyu0Y7FY2LRpU/mi/ePHj3PhwgWys7OxWq34+vpWOBmjd+/eDBo0iG7dumnRfj1T8ImI/EgHDx4kLi6OM2fOMG3atEqhdyOXL18mPj6er776qnzR/sWLFyucjNGiRQs6duxIVFRU+ckY4eHh9fSL3IuCT0SkAbn2ZIwjR45w8uRJLl++XH4yRtmi/Ztvvpno6OjynWyaN294u/LURFJmLpMPppBYkE+eaSPQ8KCrfwBzenQhsln9bGyu4BMRaQRsNhuHDh1i+/bt7Nu3j6SkJM6cOUNmZmaFkzFat25dvmi/f//+9O/fn4CAAGeXX0lcynkmp6Ry2tcCgOn5/RZwhrU0lsKLvZjZOYKxXdrY9dkKPhGRRq64uJjdu3ezfft2Dhw4wLFjx8oX7ZedjFG2aL9sks3AgQO54447nHIyxtM7DrG0KAPTADyq2fPUZmKYMN43lCUDou32fAWfiIgLy87OZtu2bezatYuDBw9y4sQJLly4QE5ODjabDT8/v0onYwwePJjIyMh6mWRTHnqeNd/k27Cadg0/BZ+IiJs6f/48W7duZffu3Rw+fJiTJ09y8eJF8vPzASqcjNGtWzf69u3L4MGDadeuXa2eF5dyntjTyRVDb/RoyMyEa0P244/hB+8sDatJXHgkYzrXfdhTwSciIhXYbDZSUlLYunUre/fuJTExkdOnT1c6GSMsLIyIiAh69OhBv379GDRoULUnY3T8Yjun/CwVhzdHj4ZXX4U77rhBUSYdC71IGx5T59+n4BMRkRqzWCx88803bN++vfxkjDNnznD16lWKi4vx8vKqcDLG7bffzoABAwjt2oMe3x6oPMRZ0+CjtNeX1KtPnWd7KvhERMQuCgsL2blzJzt37uTAgQOkpKRw/vx5srKy8Prf6RT95G7wqlvwjfAMYeXg2+tUp4JPRETq3S3rt5PSxFr5wujRkJUFZSdc9OwJM2det51bC7xJeqB/nWrRXp0iIlLvCqqbIDpzZo16fAB5pq3OtWhDOBERqXeBhn3ixh7tKPhERKTedfUPKN+RpbYMq0lX/7rvQqPgExGRejerRxe7tDPbDu1ocouIiDhElev4asqO6/jU4xMREYeY1SUCo5ZdLcOE2bdE2KUOBZ+IiDjE2C5tGO8b+qPf9ZXt1WmP7cpAQ50iIuJgOp1BRETczrLj55l0LJVT1Z3HV+TF7Fsi7NbTK29fwSciIs6SnJnLpCpOYJ+tE9hFRETsQ5NbRETErSj4RETErSj4RETErSj4RETErSj4RETErSj4RETErSj4RETErSj4RETErSj4RETErfx/ed1JeG3+qNUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([0.1783, 0.8217])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgLhUBmYJYnf"
      },
      "source": [
        ""
      ],
      "execution_count": 60,
      "outputs": []
    }
  ]
}